{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4845e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from models.model_cnn import KaninchenModel, KaninchenModelResidual, KaninchenModel_v1, KaninchenModel_v2, KaninchenModel_v3, KaninchenModel_v4, KaninchenModel_v5\n",
    "from data.datamodule import BinaryImageDataModule, ReducedSizeBinaryImageDataModule\n",
    "\n",
    "import optuna\n",
    "from training.hyperparameter_tuning import CnnOptunaTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117666f9",
   "metadata": {},
   "source": [
    "### Loading Configuration\n",
    "\n",
    "In the following steps, we will load the configuration settings using the `load_configuration` function. The configuration is stored in the `config` variable which will be used throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74321032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC Name: DESKTOP-LUKAS\n",
      "Loaded configuration from config/config_lukas.yaml\n"
     ]
    }
   ],
   "source": [
    "from config.load_configuration import load_configuration\n",
    "config = load_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcae64d",
   "metadata": {},
   "source": [
    "### Logging in to Weights & Biases (wandb)\n",
    "\n",
    "Before starting any experiment tracking, ensure you are logged in to your Weights & Biases (wandb) account. This enables automatic logging of metrics, model checkpoints, and experiment configurations. The following code logs you in to wandb:\n",
    "\n",
    "```python\n",
    "wandb.login()\n",
    "```\n",
    "If you are running this for the first time, you may be prompted to enter your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee8f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-pelz\u001b[0m (\u001b[33mHKA-EKG-Signalverarbeitung\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Wandb logger\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414378fc",
   "metadata": {},
   "source": [
    "### Setting Seeds for Reproducibility\n",
    "\n",
    "To ensure comparable and reproducible results, we set the random seed using the `seed_everything` function from PyTorch Lightning. This helps in achieving consistent behavior across multiple runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e10d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"   # disable oneDNN optimizations for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86df64",
   "metadata": {},
   "source": [
    "### Checking for GPU Devices\n",
    "\n",
    "In this step, we check for the availability of GPU devices and print the device currently being used by PyTorch. This ensures that the computations are performed on the most efficient hardware available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b717a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version:  2.7.0+cu128\n",
      "Using device:  cuda\n",
      "Cuda Version:  12.8\n",
      "NVIDIA GeForce RTX 5060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Torch Version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "if device.type == 'cuda':\n",
    "    print('Cuda Version: ', torch.version.cuda)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177b86e",
   "metadata": {},
   "source": [
    "### Defining Transformations and Instantiating DataModule\n",
    "\n",
    "In this step, we will define the necessary data transformations and initialize the `Animal_DataModule` with the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df954014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ReducedSizeBinaryImageDataset.__init__() got an unexpected keyword argument 'reduced_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m dm = ReducedSizeBinaryImageDataModule(data_dir=config[\u001b[33m'\u001b[39m\u001b[33mpath_to_split_aug_pics\u001b[39m\u001b[33m'\u001b[39m], transform=transform, batch_size=config[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m], num_workers=\u001b[32m2\u001b[39m, persistent_workers=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# dm = BinaryImageDataModule(data_dir=config['path_to_split_aug_pics'], transform=transform, batch_size=config['batch_size'], num_workers=2, persistent_workers=True)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m train_loader = dm.train_dataloader()\n\u001b[32m     17\u001b[39m val_loader = dm.val_dataloader()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\Documents\\HKA_DEV\\HKA_VDKI\\data\\datamodule.py:201\u001b[39m, in \u001b[36mReducedSizeBinaryImageDataModule.setup\u001b[39m\u001b[34m(self, stage)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_dataset = \u001b[43mReducedSizeBinaryImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/train/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m.val_dataset = ReducedSizeBinaryImageDataset(\u001b[38;5;28mself\u001b[39m.data_dir + \u001b[33m'\u001b[39m\u001b[33m/test/\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.transform, reduced_size=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m.test_dataset = ReducedSizeBinaryImageDataset(\u001b[38;5;28mself\u001b[39m.data_dir + \u001b[33m'\u001b[39m\u001b[33m/val/\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.transform, reduced_size=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: ReducedSizeBinaryImageDataset.__init__() got an unexpected keyword argument 'reduced_size'"
     ]
    }
   ],
   "source": [
    "# TODO: Define transformations here\n",
    "size = config['image_size']\n",
    "\n",
    "import data.custom_transforms as custom_transforms\n",
    "transform = v2.Compose([\n",
    "    custom_transforms.CenterCropSquare(),\n",
    "    v2.Resize((size, size)),\n",
    "    v2.ToTensor(),\n",
    "    # v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dm = ReducedSizeBinaryImageDataModule(data_dir=config['path_to_split_aug_pics'], transform=transform, batch_size=config['batch_size'], num_workers=2, persistent_workers=True)\n",
    "# dm = BinaryImageDataModule(data_dir=config['path_to_split_aug_pics'], transform=transform, batch_size=config['batch_size'], num_workers=2, persistent_workers=True)\n",
    "dm.setup()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "# Show a few images from the training set\n",
    "from torchvision.utils import make_grid\n",
    "def show_images(loader):\n",
    "    images, labels = next(iter(loader))\n",
    "    images = images[:16]  # Show only the first 16 images\n",
    "    labels = labels[:16]\n",
    "    grid = make_grid(images, nrow=4, padding=2)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "    plt.title('Sample Images')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "show_images(train_loader)\n",
    "\n",
    "print('Train dataset size:', len(dm.train_dataset))\n",
    "print('Validation dataset size:', len(dm.val_dataset))\n",
    "print('Test dataset size:', len(dm.test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c560cb9",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "In this step, we will define the model architecture and print its summary using the `ModelSummary` utility from PyTorch Lightning. This provides an overview of the model's layers, parameters, and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3442708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                | Type              | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0  | criterion           | BCEWithLogitsLoss | 0      | train\n",
      "1  | sigmoid             | Sigmoid           | 0      | train\n",
      "2  | model               | Sequential        | 1.1 M  | train\n",
      "3  | model.0             | Conv2d            | 896    | train\n",
      "4  | model.1             | BatchNorm2d       | 64     | train\n",
      "5  | model.2             | ReLU              | 0      | train\n",
      "6  | model.3             | MaxPool2d         | 0      | train\n",
      "7  | model.4             | Conv2d            | 18.5 K | train\n",
      "8  | model.5             | BatchNorm2d       | 128    | train\n",
      "9  | model.6             | ReLU              | 0      | train\n",
      "10 | model.7             | MaxPool2d         | 0      | train\n",
      "11 | model.8             | Conv2d            | 73.9 K | train\n",
      "12 | model.9             | BatchNorm2d       | 256    | train\n",
      "13 | model.10            | ReLU              | 0      | train\n",
      "14 | model.11            | MaxPool2d         | 0      | train\n",
      "15 | model.12            | Flatten           | 0      | train\n",
      "16 | model.13            | Linear            | 1.0 M  | train\n",
      "17 | model.14            | ReLU              | 0      | train\n",
      "18 | model.15            | Dropout           | 0      | train\n",
      "19 | model.16            | Linear            | 513    | train\n",
      "20 | train_accuracy      | BinaryAccuracy    | 0      | train\n",
      "21 | val_accuracy        | BinaryAccuracy    | 0      | train\n",
      "22 | val_precision       | BinaryPrecision   | 0      | train\n",
      "23 | val_recall          | BinaryRecall      | 0      | train\n",
      "24 | test_accuracy       | BinaryAccuracy    | 0      | train\n",
      "25 | init_conv           | Sequential        | 1.9 K  | train\n",
      "26 | init_conv.0         | Conv2d            | 1.8 K  | train\n",
      "27 | init_conv.1         | BatchNorm2d       | 128    | train\n",
      "28 | init_conv.2         | SiLU              | 0      | train\n",
      "29 | layer1              | Sequential        | 221 K  | train\n",
      "30 | layer1.0            | Conv2d            | 73.9 K | train\n",
      "31 | layer1.1            | BatchNorm2d       | 256    | train\n",
      "32 | layer1.2            | SiLU              | 0      | train\n",
      "33 | layer1.3            | Conv2d            | 147 K  | train\n",
      "34 | layer1.4            | BatchNorm2d       | 256    | train\n",
      "35 | layer1.5            | SiLU              | 0      | train\n",
      "36 | layer1.6            | MaxPool2d         | 0      | train\n",
      "37 | layer2              | Sequential        | 295 K  | train\n",
      "38 | layer2.0            | Conv2d            | 147 K  | train\n",
      "39 | layer2.1            | BatchNorm2d       | 256    | train\n",
      "40 | layer2.2            | SiLU              | 0      | train\n",
      "41 | layer2.3            | Conv2d            | 147 K  | train\n",
      "42 | layer2.4            | BatchNorm2d       | 256    | train\n",
      "43 | layer2.5            | SiLU              | 0      | train\n",
      "44 | layer2.6            | MaxPool2d         | 0      | train\n",
      "45 | layer3              | Sequential        | 886 K  | train\n",
      "46 | layer3.0            | Conv2d            | 295 K  | train\n",
      "47 | layer3.1            | BatchNorm2d       | 512    | train\n",
      "48 | layer3.2            | SiLU              | 0      | train\n",
      "49 | layer3.3            | Conv2d            | 590 K  | train\n",
      "50 | layer3.4            | BatchNorm2d       | 512    | train\n",
      "51 | layer3.5            | SiLU              | 0      | train\n",
      "52 | layer3.6            | MaxPool2d         | 0      | train\n",
      "53 | layer4              | ResidualBlock     | 1.2 M  | train\n",
      "54 | layer4.conv_block   | Sequential        | 1.2 M  | train\n",
      "55 | layer4.conv_block.0 | Conv2d            | 590 K  | train\n",
      "56 | layer4.conv_block.1 | BatchNorm2d       | 512    | train\n",
      "57 | layer4.conv_block.2 | ReLU              | 0      | train\n",
      "58 | layer4.conv_block.3 | Conv2d            | 590 K  | train\n",
      "59 | layer4.conv_block.4 | BatchNorm2d       | 512    | train\n",
      "60 | layer4.skip         | Sequential        | 66.3 K | train\n",
      "61 | layer4.skip.0       | Conv2d            | 65.8 K | train\n",
      "62 | layer4.skip.1       | BatchNorm2d       | 512    | train\n",
      "63 | layer4.relu         | ReLU              | 0      | train\n",
      "64 | flatten             | Flatten           | 0      | train\n",
      "65 | fc                  | Linear            | 16.4 K | train\n",
      "-------------------------------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.252    Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "KaninchenModel_v1\n"
     ]
    }
   ],
   "source": [
    "#model = CatsDogsModel()\n",
    "# model = KaninchenModel()\n",
    "model = KaninchenModel_v1()\n",
    "print(ModelSummary(model, max_depth=-1))  \n",
    "print(type(model).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62271018",
   "metadata": {},
   "source": [
    "### Training the Model and Logging with Weights & Biases\n",
    "\n",
    "In this step, we initialize the Wandb logger and configure the experiment name to include a timestamp for better tracking. The `Trainer` from PyTorch Lightning is set up with the Wandb logger and an early stopping callback to monitor validation loss and prevent overfitting. After training, the Wandb run is finished, and the trained model checkpoint is saved with a unique filename containing the current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250601_182520-nvfjxu23</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/nvfjxu23' target=\"_blank\">binaryClassification_CNN_KaninchenModel_v1_2025-06-01_18-25-20</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/nvfjxu23' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/nvfjxu23</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0  | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "1  | sigmoid        | Sigmoid           | 0      | train\n",
      "2  | model          | Sequential        | 1.1 M  | train\n",
      "3  | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4  | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5  | val_precision  | BinaryPrecision   | 0      | train\n",
      "6  | val_recall     | BinaryRecall      | 0      | train\n",
      "7  | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "8  | init_conv      | Sequential        | 1.9 K  | train\n",
      "9  | layer1         | Sequential        | 221 K  | train\n",
      "10 | layer2         | Sequential        | 295 K  | train\n",
      "11 | layer3         | Sequential        | 886 K  | train\n",
      "12 | layer4         | ResidualBlock     | 1.2 M  | train\n",
      "13 | flatten        | Flatten           | 0      | train\n",
      "14 | fc             | Linear            | 16.4 K | train\n",
      "--------------------------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.252    Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  78%|███████▊  | 42/54 [13:05<03:44,  0.05it/s, v_num=xu23, val_loss=0.583]"
     ]
    }
   ],
   "source": [
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback (https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/', #data_directory, \n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "# Create a filename with date identifier\n",
    "model_filename = f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}.ckpt\"\n",
    "\n",
    "# Save the model's state_dict to the path specified in config\n",
    "save_path = os.path.join(os.path.dirname(config['path_to_models']), model_filename)\n",
    "trainer.save_checkpoint(save_path)\n",
    "print(f\"Model checkpoint saved as {save_path}\")\n",
    "config['path_to_model'] = save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95161133",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization with Optuna\n",
    "\n",
    "This section performs automated hyperparameter tuning using Optuna to find the optimal model configuration. The optimization process searches for hyperparameters that minimize validation loss across multiple trials, helping to improve model performance beyond manual tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576170ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-01 17:30:27,053] A new study created in memory with name: no-name-708c7fc9-52b8-443f-9e48-87978ea44278\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250601_173027-fx1n6zz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/fx1n6zz9' target=\"_blank\">KaninchenModel_bs32_img128_optAdam_lr2e-03_wd6e-05_sch_CosineAnnealingLR_2025-06-01_17-30</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/fx1n6zz9' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/fx1n6zz9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0  | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "1  | sigmoid        | Sigmoid           | 0      | train\n",
      "2  | model          | Sequential        | 13.1 M | train\n",
      "3  | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4  | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5  | val_precision  | BinaryPrecision   | 0      | train\n",
      "6  | val_recall     | BinaryRecall      | 0      | train\n",
      "7  | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "8  | conv1          | Sequential        | 39.0 K | train\n",
      "9  | conv2          | Sequential        | 221 K  | train\n",
      "10 | conv3          | Sequential        | 886 K  | train\n",
      "11 | conv4          | Sequential        | 3.5 M  | train\n",
      "12 | conv5          | Sequential        | 3.5 M  | train\n",
      "13 | cnn            | Sequential        | 4.7 M  | train\n",
      "14 | classifier     | Sequential        | 8.4 M  | train\n",
      "--------------------------------------------------------------\n",
      "16.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.6 M    Total params\n",
      "66.481    Total estimated model params size (MB)\n",
      "55        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization\n",
    "import datetime\n",
    "config['sweep_id'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "def objective(trial):\n",
    "    model = KaninchenModel                  # or another model's class, depending on your choice\n",
    "    trainer = CnnOptunaTrainer(\n",
    "        model=model,                        # Function to create the model\n",
    "        config=config,\n",
    "        normalize_mean=None, #[0.485, 0.456, 0.406], \n",
    "        normalize_std=None, #[0.229, 0.224, 0.225],\n",
    "        dataset_name=\"DwarfRabbits-binary\"\n",
    "    )\n",
    "    return trainer.run_training(trial)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")  # because we minimize val_loss\n",
    "\n",
    "# Set verbosity to WARNING to reduce output clutter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Start the hyperparameter optimization\n",
    "study.optimize(objective, n_trials=config['number_of_trials'])\n",
    "# study.optimize(objective, n_trials=3)\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best value (val_loss):\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378aefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94714cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a07eb",
   "metadata": {},
   "source": [
    "# Predict with the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import torch\n",
    "# # Load the saved model weights from the path specified in config\n",
    "\n",
    "# def predict_image(path, model):\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((150, 150)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "#     ])\n",
    "\n",
    "#     img = Image.open(path).convert('RGB')\n",
    "#     img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         pred = model(img)\n",
    "#         result = \"Dog\" if pred.item() > 0.5 else \"Cat\"\n",
    "#     print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738413b",
   "metadata": {},
   "source": [
    "### Loading and Evaluating the Trained Model\n",
    "\n",
    "The trained model is loaded from the checkpoint specified in the configuration. If the checkpoint exists, the model weights are restored and the model is set to evaluation mode. PyTorch Lightning's `Trainer` is then used to evaluate the model on the test dataset, providing a streamlined way to assess model performance after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fc6fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for KaninchenModel:\n\tMissing key(s) in state_dict: \"model.0.0.0.weight\", \"model.0.0.0.bias\", \"model.0.0.1.weight\", \"model.0.0.1.bias\", \"model.0.0.1.running_mean\", \"model.0.0.1.running_var\", \"model.0.0.3.weight\", \"model.0.0.3.bias\", \"model.0.0.4.weight\", \"model.0.0.4.bias\", \"model.0.0.4.running_mean\", \"model.0.0.4.running_var\", \"model.0.1.0.weight\", \"model.0.1.0.bias\", \"model.0.1.1.weight\", \"model.0.1.1.bias\", \"model.0.1.1.running_mean\", \"model.0.1.1.running_var\", \"model.0.1.3.weight\", \"model.0.1.3.bias\", \"model.0.1.4.weight\", \"model.0.1.4.bias\", \"model.0.1.4.running_mean\", \"model.0.1.4.running_var\", \"model.0.2.0.weight\", \"model.0.2.0.bias\", \"model.0.2.1.weight\", \"model.0.2.1.bias\", \"model.0.2.1.running_mean\", \"model.0.2.1.running_var\", \"model.0.2.3.weight\", \"model.0.2.3.bias\", \"model.0.2.4.weight\", \"model.0.2.4.bias\", \"model.0.2.4.running_mean\", \"model.0.2.4.running_var\", \"model.0.3.0.weight\", \"model.0.3.0.bias\", \"model.0.3.1.weight\", \"model.0.3.1.bias\", \"model.0.3.1.running_mean\", \"model.0.3.1.running_var\", \"model.0.3.3.weight\", \"model.0.3.3.bias\", \"model.0.3.4.weight\", \"model.0.3.4.bias\", \"model.0.3.4.running_mean\", \"model.0.3.4.running_var\", \"model.1.1.weight\", \"model.1.1.bias\", \"model.1.4.weight\", \"model.1.4.bias\", \"conv1.0.weight\", \"conv1.0.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.4.weight\", \"conv1.4.bias\", \"conv1.4.running_mean\", \"conv1.4.running_var\", \"conv2.0.weight\", \"conv2.0.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.4.weight\", \"conv2.4.bias\", \"conv2.4.running_mean\", \"conv2.4.running_var\", \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv5.0.weight\", \"conv5.0.bias\", \"conv5.1.weight\", \"conv5.1.bias\", \"conv5.1.running_mean\", \"conv5.1.running_var\", \"conv5.3.weight\", \"conv5.3.bias\", \"conv5.4.weight\", \"conv5.4.bias\", \"conv5.4.running_mean\", \"conv5.4.running_var\", \"cnn.0.0.weight\", \"cnn.0.0.bias\", \"cnn.0.1.weight\", \"cnn.0.1.bias\", \"cnn.0.1.running_mean\", \"cnn.0.1.running_var\", \"cnn.0.3.weight\", \"cnn.0.3.bias\", \"cnn.0.4.weight\", \"cnn.0.4.bias\", \"cnn.0.4.running_mean\", \"cnn.0.4.running_var\", \"cnn.1.0.weight\", \"cnn.1.0.bias\", \"cnn.1.1.weight\", \"cnn.1.1.bias\", \"cnn.1.1.running_mean\", \"cnn.1.1.running_var\", \"cnn.1.3.weight\", \"cnn.1.3.bias\", \"cnn.1.4.weight\", \"cnn.1.4.bias\", \"cnn.1.4.running_mean\", \"cnn.1.4.running_var\", \"cnn.2.0.weight\", \"cnn.2.0.bias\", \"cnn.2.1.weight\", \"cnn.2.1.bias\", \"cnn.2.1.running_mean\", \"cnn.2.1.running_var\", \"cnn.2.3.weight\", \"cnn.2.3.bias\", \"cnn.2.4.weight\", \"cnn.2.4.bias\", \"cnn.2.4.running_mean\", \"cnn.2.4.running_var\", \"cnn.3.0.weight\", \"cnn.3.0.bias\", \"cnn.3.1.weight\", \"cnn.3.1.bias\", \"cnn.3.1.running_mean\", \"cnn.3.1.running_var\", \"cnn.3.3.weight\", \"cnn.3.3.bias\", \"cnn.3.4.weight\", \"cnn.3.4.bias\", \"cnn.3.4.running_mean\", \"cnn.3.4.running_var\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\". \n\tUnexpected key(s) in state_dict: \"init_conv.0.weight\", \"init_conv.0.bias\", \"init_conv.1.weight\", \"init_conv.1.bias\", \"init_conv.1.running_mean\", \"init_conv.1.running_var\", \"init_conv.1.num_batches_tracked\", \"layer1.0.weight\", \"layer1.0.bias\", \"layer1.1.weight\", \"layer1.1.bias\", \"layer1.1.running_mean\", \"layer1.1.running_var\", \"layer1.1.num_batches_tracked\", \"layer1.3.weight\", \"layer1.3.bias\", \"layer1.4.weight\", \"layer1.4.bias\", \"layer1.4.running_mean\", \"layer1.4.running_var\", \"layer1.4.num_batches_tracked\", \"layer2.0.weight\", \"layer2.0.bias\", \"layer2.1.weight\", \"layer2.1.bias\", \"layer2.1.running_mean\", \"layer2.1.running_var\", \"layer2.1.num_batches_tracked\", \"layer2.3.weight\", \"layer2.3.bias\", \"layer2.4.weight\", \"layer2.4.bias\", \"layer2.4.running_mean\", \"layer2.4.running_var\", \"layer2.4.num_batches_tracked\", \"layer3.0.weight\", \"layer3.0.bias\", \"layer3.1.weight\", \"layer3.1.bias\", \"layer3.1.running_mean\", \"layer3.1.running_var\", \"layer3.1.num_batches_tracked\", \"layer3.3.weight\", \"layer3.3.bias\", \"layer3.4.weight\", \"layer3.4.bias\", \"layer3.4.running_mean\", \"layer3.4.running_var\", \"layer3.4.num_batches_tracked\", \"layer4.conv_block.0.weight\", \"layer4.conv_block.0.bias\", \"layer4.conv_block.1.weight\", \"layer4.conv_block.1.bias\", \"layer4.conv_block.1.running_mean\", \"layer4.conv_block.1.running_var\", \"layer4.conv_block.1.num_batches_tracked\", \"layer4.conv_block.3.weight\", \"layer4.conv_block.3.bias\", \"layer4.conv_block.4.weight\", \"layer4.conv_block.4.bias\", \"layer4.conv_block.4.running_mean\", \"layer4.conv_block.4.running_var\", \"layer4.conv_block.4.num_batches_tracked\", \"layer4.skip.0.weight\", \"layer4.skip.0.bias\", \"layer4.skip.1.weight\", \"layer4.skip.1.bias\", \"layer4.skip.1.running_mean\", \"layer4.skip.1.running_var\", \"layer4.skip.1.num_batches_tracked\", \"fc.weight\", \"fc.bias\", \"model.4.weight\", \"model.4.bias\", \"model.5.weight\", \"model.5.bias\", \"model.5.running_mean\", \"model.5.running_var\", \"model.5.num_batches_tracked\", \"model.8.weight\", \"model.8.bias\", \"model.9.weight\", \"model.9.bias\", \"model.9.running_mean\", \"model.9.running_var\", \"model.9.num_batches_tracked\", \"model.13.weight\", \"model.13.bias\", \"model.16.weight\", \"model.16.bias\", \"model.0.weight\", \"model.0.bias\", \"model.1.weight\", \"model.1.bias\", \"model.1.running_mean\", \"model.1.running_var\", \"model.1.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model_path = config[\u001b[33m'\u001b[39m\u001b[33mpath_to_model\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mand\u001b[39;00m os.path.exists(model_path):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#model = CatsDogsModel.load_from_checkpoint(model_path, map_location=device)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     model = \u001b[43mKaninchenModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded model weights from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1581\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1499\u001b[39m     **kwargs: Any,\n\u001b[32m   1500\u001b[39m ) -> Self:\n\u001b[32m   1501\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1503\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1579\u001b[39m \n\u001b[32m   1580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1582\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1587\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1588\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:91\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, **kwargs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl.LightningModule):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     model = \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     state_dict = checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:187\u001b[39m, in \u001b[36m_load_state\u001b[39m\u001b[34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[39m\n\u001b[32m    184\u001b[39m     obj.on_load_checkpoint(checkpoint)\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m keys = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate_dict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m keys.missing_keys:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for KaninchenModel:\n\tMissing key(s) in state_dict: \"model.0.0.0.weight\", \"model.0.0.0.bias\", \"model.0.0.1.weight\", \"model.0.0.1.bias\", \"model.0.0.1.running_mean\", \"model.0.0.1.running_var\", \"model.0.0.3.weight\", \"model.0.0.3.bias\", \"model.0.0.4.weight\", \"model.0.0.4.bias\", \"model.0.0.4.running_mean\", \"model.0.0.4.running_var\", \"model.0.1.0.weight\", \"model.0.1.0.bias\", \"model.0.1.1.weight\", \"model.0.1.1.bias\", \"model.0.1.1.running_mean\", \"model.0.1.1.running_var\", \"model.0.1.3.weight\", \"model.0.1.3.bias\", \"model.0.1.4.weight\", \"model.0.1.4.bias\", \"model.0.1.4.running_mean\", \"model.0.1.4.running_var\", \"model.0.2.0.weight\", \"model.0.2.0.bias\", \"model.0.2.1.weight\", \"model.0.2.1.bias\", \"model.0.2.1.running_mean\", \"model.0.2.1.running_var\", \"model.0.2.3.weight\", \"model.0.2.3.bias\", \"model.0.2.4.weight\", \"model.0.2.4.bias\", \"model.0.2.4.running_mean\", \"model.0.2.4.running_var\", \"model.0.3.0.weight\", \"model.0.3.0.bias\", \"model.0.3.1.weight\", \"model.0.3.1.bias\", \"model.0.3.1.running_mean\", \"model.0.3.1.running_var\", \"model.0.3.3.weight\", \"model.0.3.3.bias\", \"model.0.3.4.weight\", \"model.0.3.4.bias\", \"model.0.3.4.running_mean\", \"model.0.3.4.running_var\", \"model.1.1.weight\", \"model.1.1.bias\", \"model.1.4.weight\", \"model.1.4.bias\", \"conv1.0.weight\", \"conv1.0.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.4.weight\", \"conv1.4.bias\", \"conv1.4.running_mean\", \"conv1.4.running_var\", \"conv2.0.weight\", \"conv2.0.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.4.weight\", \"conv2.4.bias\", \"conv2.4.running_mean\", \"conv2.4.running_var\", \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv5.0.weight\", \"conv5.0.bias\", \"conv5.1.weight\", \"conv5.1.bias\", \"conv5.1.running_mean\", \"conv5.1.running_var\", \"conv5.3.weight\", \"conv5.3.bias\", \"conv5.4.weight\", \"conv5.4.bias\", \"conv5.4.running_mean\", \"conv5.4.running_var\", \"cnn.0.0.weight\", \"cnn.0.0.bias\", \"cnn.0.1.weight\", \"cnn.0.1.bias\", \"cnn.0.1.running_mean\", \"cnn.0.1.running_var\", \"cnn.0.3.weight\", \"cnn.0.3.bias\", \"cnn.0.4.weight\", \"cnn.0.4.bias\", \"cnn.0.4.running_mean\", \"cnn.0.4.running_var\", \"cnn.1.0.weight\", \"cnn.1.0.bias\", \"cnn.1.1.weight\", \"cnn.1.1.bias\", \"cnn.1.1.running_mean\", \"cnn.1.1.running_var\", \"cnn.1.3.weight\", \"cnn.1.3.bias\", \"cnn.1.4.weight\", \"cnn.1.4.bias\", \"cnn.1.4.running_mean\", \"cnn.1.4.running_var\", \"cnn.2.0.weight\", \"cnn.2.0.bias\", \"cnn.2.1.weight\", \"cnn.2.1.bias\", \"cnn.2.1.running_mean\", \"cnn.2.1.running_var\", \"cnn.2.3.weight\", \"cnn.2.3.bias\", \"cnn.2.4.weight\", \"cnn.2.4.bias\", \"cnn.2.4.running_mean\", \"cnn.2.4.running_var\", \"cnn.3.0.weight\", \"cnn.3.0.bias\", \"cnn.3.1.weight\", \"cnn.3.1.bias\", \"cnn.3.1.running_mean\", \"cnn.3.1.running_var\", \"cnn.3.3.weight\", \"cnn.3.3.bias\", \"cnn.3.4.weight\", \"cnn.3.4.bias\", \"cnn.3.4.running_mean\", \"cnn.3.4.running_var\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\". \n\tUnexpected key(s) in state_dict: \"init_conv.0.weight\", \"init_conv.0.bias\", \"init_conv.1.weight\", \"init_conv.1.bias\", \"init_conv.1.running_mean\", \"init_conv.1.running_var\", \"init_conv.1.num_batches_tracked\", \"layer1.0.weight\", \"layer1.0.bias\", \"layer1.1.weight\", \"layer1.1.bias\", \"layer1.1.running_mean\", \"layer1.1.running_var\", \"layer1.1.num_batches_tracked\", \"layer1.3.weight\", \"layer1.3.bias\", \"layer1.4.weight\", \"layer1.4.bias\", \"layer1.4.running_mean\", \"layer1.4.running_var\", \"layer1.4.num_batches_tracked\", \"layer2.0.weight\", \"layer2.0.bias\", \"layer2.1.weight\", \"layer2.1.bias\", \"layer2.1.running_mean\", \"layer2.1.running_var\", \"layer2.1.num_batches_tracked\", \"layer2.3.weight\", \"layer2.3.bias\", \"layer2.4.weight\", \"layer2.4.bias\", \"layer2.4.running_mean\", \"layer2.4.running_var\", \"layer2.4.num_batches_tracked\", \"layer3.0.weight\", \"layer3.0.bias\", \"layer3.1.weight\", \"layer3.1.bias\", \"layer3.1.running_mean\", \"layer3.1.running_var\", \"layer3.1.num_batches_tracked\", \"layer3.3.weight\", \"layer3.3.bias\", \"layer3.4.weight\", \"layer3.4.bias\", \"layer3.4.running_mean\", \"layer3.4.running_var\", \"layer3.4.num_batches_tracked\", \"layer4.conv_block.0.weight\", \"layer4.conv_block.0.bias\", \"layer4.conv_block.1.weight\", \"layer4.conv_block.1.bias\", \"layer4.conv_block.1.running_mean\", \"layer4.conv_block.1.running_var\", \"layer4.conv_block.1.num_batches_tracked\", \"layer4.conv_block.3.weight\", \"layer4.conv_block.3.bias\", \"layer4.conv_block.4.weight\", \"layer4.conv_block.4.bias\", \"layer4.conv_block.4.running_mean\", \"layer4.conv_block.4.running_var\", \"layer4.conv_block.4.num_batches_tracked\", \"layer4.skip.0.weight\", \"layer4.skip.0.bias\", \"layer4.skip.1.weight\", \"layer4.skip.1.bias\", \"layer4.skip.1.running_mean\", \"layer4.skip.1.running_var\", \"layer4.skip.1.num_batches_tracked\", \"fc.weight\", \"fc.bias\", \"model.4.weight\", \"model.4.bias\", \"model.5.weight\", \"model.5.bias\", \"model.5.running_mean\", \"model.5.running_var\", \"model.5.num_batches_tracked\", \"model.8.weight\", \"model.8.bias\", \"model.9.weight\", \"model.9.bias\", \"model.9.running_mean\", \"model.9.running_var\", \"model.9.num_batches_tracked\", \"model.13.weight\", \"model.13.bias\", \"model.16.weight\", \"model.16.bias\", \"model.0.weight\", \"model.0.bias\", \"model.1.weight\", \"model.1.bias\", \"model.1.running_mean\", \"model.1.running_var\", \"model.1.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "model_path = config['path_to_model']\n",
    "if model_path and os.path.exists(model_path):\n",
    "    #model = CatsDogsModel.load_from_checkpoint(model_path, map_location=device)\n",
    "    model = KaninchenModel.load_from_checkpoint(model_path, map_location=device)\n",
    "    print(f\"Loaded model weights from {model_path}\")\n",
    "else:\n",
    "    print(\"Model path not found or not specified in config.\")\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Pytorch Lightning's Trainer can be used to test the model\n",
    "trainer = Trainer()\n",
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDKI-Projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

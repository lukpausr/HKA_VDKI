{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4845e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from models.model_cnn import KaninchenModel, KaninchenModelResidual, KaninchenModel_v1, KaninchenModel_v2, KaninchenModel_v3, KaninchenModel_v4, KaninchenModel_v5\n",
    "from data.datamodule import BinaryImageDataModule, ReducedSizeBinaryImageDataModule\n",
    "\n",
    "import optuna\n",
    "from training.hyperparameter_tuning import CnnOptunaTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117666f9",
   "metadata": {},
   "source": [
    "### Loading Configuration\n",
    "\n",
    "In the following steps, we will load the configuration settings using the `load_configuration` function. The configuration is stored in the `config` variable which will be used throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74321032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC Name: DESKTOP-LUKAS\n",
      "Loaded configuration from config/config_lukas.yaml\n"
     ]
    }
   ],
   "source": [
    "from config.load_configuration import load_configuration\n",
    "config = load_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcae64d",
   "metadata": {},
   "source": [
    "### Logging in to Weights & Biases (wandb)\n",
    "\n",
    "Before starting any experiment tracking, ensure you are logged in to your Weights & Biases (wandb) account. This enables automatic logging of metrics, model checkpoints, and experiment configurations. The following code logs you in to wandb:\n",
    "\n",
    "```python\n",
    "wandb.login()\n",
    "```\n",
    "If you are running this for the first time, you may be prompted to enter your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee8f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-pelz\u001b[0m (\u001b[33mHKA-EKG-Signalverarbeitung\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Wandb logger\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414378fc",
   "metadata": {},
   "source": [
    "### Setting Seeds for Reproducibility\n",
    "\n",
    "To ensure comparable and reproducible results, we set the random seed using the `seed_everything` function from PyTorch Lightning. This helps in achieving consistent behavior across multiple runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e10d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"   # disable oneDNN optimizations for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86df64",
   "metadata": {},
   "source": [
    "### Checking for GPU Devices\n",
    "\n",
    "In this step, we check for the availability of GPU devices and print the device currently being used by PyTorch. This ensures that the computations are performed on the most efficient hardware available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b717a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version:  2.7.0+cu128\n",
      "Using device:  cuda\n",
      "Cuda Version:  12.8\n",
      "NVIDIA GeForce RTX 5060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Torch Version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "if device.type == 'cuda':\n",
    "    print('Cuda Version: ', torch.version.cuda)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177b86e",
   "metadata": {},
   "source": [
    "### Defining Transformations and Instantiating DataModule\n",
    "\n",
    "In this step, we will define the necessary data transformations and initialize the `Animal_DataModule` with the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df954014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define transformations here\n",
    "import os\n",
    "\n",
    "size = config['image_size']\n",
    "\n",
    "import data.custom_transforms as custom_transforms\n",
    "transform = v2.Compose([\n",
    "    custom_transforms.CenterCropSquare(),\n",
    "    v2.Resize((size, size)),\n",
    "    v2.ToTensor(),\n",
    "    # v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dm = ReducedSizeBinaryImageDataModule(data_dir=config['path_to_split_aug_pics'], transform=transform, batch_size=config['batch_size'], num_workers=6) #, persistent_workers=True)\n",
    "# dm = BinaryImageDataModule(data_dir=config['path_to_split_aug_pics'], transform=transform, batch_size=config['batch_size'], num_workers=2, persistent_workers=True)\n",
    "# dm.setup()\n",
    "\n",
    "# train_loader = dm.train_dataloader()\n",
    "# val_loader = dm.val_dataloader()\n",
    "# test_loader = dm.test_dataloader()\n",
    "\n",
    "# # Show a few images from the training set\n",
    "# from torchvision.utils import make_grid\n",
    "# def show_images(loader):\n",
    "#     images, labels = next(iter(loader))\n",
    "#     images = images[:16]  # Show only the first 16 images\n",
    "#     labels = labels[:16]\n",
    "#     grid = make_grid(images, nrow=4, padding=2)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "#     plt.title('Sample Images')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "# show_images(train_loader)\n",
    "\n",
    "# print('Train dataset size:', len(dm.train_dataset))\n",
    "# print('Validation dataset size:', len(dm.val_dataset))\n",
    "# print('Test dataset size:', len(dm.test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c560cb9",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "In this step, we will define the model architecture and print its summary using the `ModelSummary` utility from PyTorch Lightning. This provides an overview of the model's layers, parameters, and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3442708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CatsDogsModel()\n",
    "# model = KaninchenModel()\n",
    "model = KaninchenModel_v1()\n",
    "print(ModelSummary(model, max_depth=-1))  \n",
    "print(type(model).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62271018",
   "metadata": {},
   "source": [
    "### Training the Model and Logging with Weights & Biases\n",
    "\n",
    "In this step, we initialize the Wandb logger and configure the experiment name to include a timestamp for better tracking. The `Trainer` from PyTorch Lightning is set up with the Wandb logger and an early stopping callback to monitor validation loss and prevent overfitting. After training, the Wandb run is finished, and the trained model checkpoint is saved with a unique filename containing the current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback (https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/', #data_directory, \n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "# Create a filename with date identifier\n",
    "model_filename = f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}.ckpt\"\n",
    "\n",
    "# Save the model's state_dict to the path specified in config\n",
    "save_path = os.path.join(os.path.dirname(config['path_to_models']), model_filename)\n",
    "trainer.save_checkpoint(save_path)\n",
    "print(f\"Model checkpoint saved as {save_path}\")\n",
    "config['path_to_model'] = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                | Type              | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0  | criterion           | BCEWithLogitsLoss | 0      | train\n",
      "1  | sigmoid             | Sigmoid           | 0      | train\n",
      "2  | model               | Sequential        | 1.1 M  | train\n",
      "3  | model.0             | Conv2d            | 896    | train\n",
      "4  | model.1             | BatchNorm2d       | 64     | train\n",
      "5  | model.2             | ReLU              | 0      | train\n",
      "6  | model.3             | MaxPool2d         | 0      | train\n",
      "7  | model.4             | Conv2d            | 18.5 K | train\n",
      "8  | model.5             | BatchNorm2d       | 128    | train\n",
      "9  | model.6             | ReLU              | 0      | train\n",
      "10 | model.7             | MaxPool2d         | 0      | train\n",
      "11 | model.8             | Conv2d            | 73.9 K | train\n",
      "12 | model.9             | BatchNorm2d       | 256    | train\n",
      "13 | model.10            | ReLU              | 0      | train\n",
      "14 | model.11            | MaxPool2d         | 0      | train\n",
      "15 | model.12            | Flatten           | 0      | train\n",
      "16 | model.13            | Linear            | 1.0 M  | train\n",
      "17 | model.14            | ReLU              | 0      | train\n",
      "18 | model.15            | Dropout           | 0      | train\n",
      "19 | model.16            | Linear            | 513    | train\n",
      "20 | train_accuracy      | BinaryAccuracy    | 0      | train\n",
      "21 | val_accuracy        | BinaryAccuracy    | 0      | train\n",
      "22 | val_precision       | BinaryPrecision   | 0      | train\n",
      "23 | val_recall          | BinaryRecall      | 0      | train\n",
      "24 | test_accuracy       | BinaryAccuracy    | 0      | train\n",
      "25 | init_conv           | Sequential        | 3.8 K  | train\n",
      "26 | init_conv.0         | Conv2d            | 3.6 K  | train\n",
      "27 | init_conv.1         | BatchNorm2d       | 256    | train\n",
      "28 | init_conv.2         | ReLU              | 0      | train\n",
      "29 | layer1              | Sequential        | 295 K  | train\n",
      "30 | layer1.0            | Conv2d            | 147 K  | train\n",
      "31 | layer1.1            | BatchNorm2d       | 256    | train\n",
      "32 | layer1.2            | ReLU              | 0      | train\n",
      "33 | layer1.3            | Conv2d            | 147 K  | train\n",
      "34 | layer1.4            | BatchNorm2d       | 256    | train\n",
      "35 | layer1.5            | ReLU              | 0      | train\n",
      "36 | layer1.6            | MaxPool2d         | 0      | train\n",
      "37 | layer2              | Sequential        | 886 K  | train\n",
      "38 | layer2.0            | Conv2d            | 295 K  | train\n",
      "39 | layer2.1            | BatchNorm2d       | 512    | train\n",
      "40 | layer2.2            | ReLU              | 0      | train\n",
      "41 | layer2.3            | Conv2d            | 590 K  | train\n",
      "42 | layer2.4            | BatchNorm2d       | 512    | train\n",
      "43 | layer2.5            | ReLU              | 0      | train\n",
      "44 | layer2.6            | MaxPool2d         | 0      | train\n",
      "45 | layer3              | Sequential        | 1.2 M  | train\n",
      "46 | layer3.0            | Conv2d            | 590 K  | train\n",
      "47 | layer3.1            | BatchNorm2d       | 512    | train\n",
      "48 | layer3.2            | ReLU              | 0      | train\n",
      "49 | layer3.3            | Conv2d            | 590 K  | train\n",
      "50 | layer3.4            | BatchNorm2d       | 512    | train\n",
      "51 | layer3.5            | ReLU              | 0      | train\n",
      "52 | layer3.6            | MaxPool2d         | 0      | train\n",
      "53 | layer4              | Sequential        | 3.5 M  | train\n",
      "54 | layer4.0            | Conv2d            | 1.2 M  | train\n",
      "55 | layer4.1            | BatchNorm2d       | 1.0 K  | train\n",
      "56 | layer4.2            | ReLU              | 0      | train\n",
      "57 | layer4.3            | Conv2d            | 2.4 M  | train\n",
      "58 | layer4.4            | BatchNorm2d       | 1.0 K  | train\n",
      "59 | layer4.5            | ReLU              | 0      | train\n",
      "60 | layer4.6            | MaxPool2d         | 0      | train\n",
      "61 | layer5              | ResidualBlock     | 5.0 M  | train\n",
      "62 | layer5.conv_block   | Sequential        | 4.7 M  | train\n",
      "63 | layer5.conv_block.0 | Conv2d            | 2.4 M  | train\n",
      "64 | layer5.conv_block.1 | BatchNorm2d       | 1.0 K  | train\n",
      "65 | layer5.conv_block.2 | ReLU              | 0      | train\n",
      "66 | layer5.conv_block.3 | Conv2d            | 2.4 M  | train\n",
      "67 | layer5.conv_block.4 | BatchNorm2d       | 1.0 K  | train\n",
      "68 | layer5.skip         | Sequential        | 263 K  | train\n",
      "69 | layer5.skip.0       | Conv2d            | 262 K  | train\n",
      "70 | layer5.skip.1       | BatchNorm2d       | 1.0 K  | train\n",
      "71 | layer5.relu         | ReLU              | 0      | train\n",
      "72 | pool                | AdaptiveAvgPool2d | 0      | train\n",
      "73 | flatten             | Flatten           | 0      | train\n",
      "74 | fc                  | Linear            | 513    | train\n",
      "-------------------------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.0 M    Total params\n",
      "48.153    Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "KaninchenModel_v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250602_192858-7tg7je5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/7tg7je5w' target=\"_blank\">binaryClassification_CNN_KaninchenModel_v2_2025-06-02_19-28-58</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/7tg7je5w' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/7tg7je5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0  | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "1  | sigmoid        | Sigmoid           | 0      | train\n",
      "2  | model          | Sequential        | 1.1 M  | train\n",
      "3  | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4  | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5  | val_precision  | BinaryPrecision   | 0      | train\n",
      "6  | val_recall     | BinaryRecall      | 0      | train\n",
      "7  | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "8  | init_conv      | Sequential        | 3.8 K  | train\n",
      "9  | layer1         | Sequential        | 295 K  | train\n",
      "10 | layer2         | Sequential        | 886 K  | train\n",
      "11 | layer3         | Sequential        | 1.2 M  | train\n",
      "12 | layer4         | Sequential        | 3.5 M  | train\n",
      "13 | layer5         | ResidualBlock     | 5.0 M  | train\n",
      "14 | pool           | AdaptiveAvgPool2d | 0      | train\n",
      "15 | flatten        | Flatten           | 0      | train\n",
      "16 | fc             | Linear            | 513    | train\n",
      "--------------------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.0 M    Total params\n",
      "48.153    Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 161/161 [00:50<00:00,  3.17it/s, v_num=je5w, val_loss=0.536]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>▁▄▇▇▅▆▄▇▇██▇█▆█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>▅▇▆▄▅▅▅▆▅▆▇▃▂▅█▅▂▄▃▄▃▅▄▃▆▄▄▄▂▂▃▃▄▃▁▂▁▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▇▆▆▇▄▇▄█▇▇█▇▇</td></tr><tr><td>val_loss</td><td>▄▂▂▂▂█▁▄▁▂▂▂▅▂</td></tr><tr><td>val_precision</td><td>▁▅▄▅▆▃▆▃▇▅▆▆█▅</td></tr><tr><td>val_recall</td><td>█▄▅▂▃▅▄█▄▇▅▇▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.8136</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>train_acc</td><td>0.81328</td></tr><tr><td>train_loss</td><td>0.39204</td></tr><tr><td>trainer/global_step</td><td>2253</td></tr><tr><td>val_acc</td><td>0.73072</td></tr><tr><td>val_loss</td><td>0.53582</td></tr><tr><td>val_precision</td><td>0.57259</td></tr><tr><td>val_recall</td><td>0.73125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binaryClassification_CNN_KaninchenModel_v2_2025-06-02_19-28-58</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/7tg7je5w' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/7tg7je5w</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen</a><br>Synced 5 W&B file(s), 45 media file(s), 60 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250602_192858-7tg7je5w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved as C:\\Users\\lukas\\SynologyDrive_IMS/SS25_MSYS_KAER-AI-PoseAct/21_Test_Data/Models/CNN\\binaryClassification_CNN_KaninchenModel_v2_2025-06-02_19-28-58.ckpt\n",
      "Completed training for KaninchenModel_v2\n"
     ]
    }
   ],
   "source": [
    "# List of all model classes to train\n",
    "model_classes = [KaninchenModel_v1, KaninchenModel_v2, KaninchenModel_v3, KaninchenModel_v4, KaninchenModel_v5, KaninchenModelResidual]\n",
    "\n",
    "import datetime\n",
    "for model_class in model_classes:\n",
    "    # Create model instance\n",
    "    model = model_class()\n",
    "    print(ModelSummary(model, max_depth=-1))  \n",
    "    print(type(model).__name__)\n",
    "\n",
    "    # Initialize the Wandb logger\n",
    "    # add time to the name of the experiment\n",
    "    now = datetime.datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # Initialize wandb logger\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config['wandb_project_name'],\n",
    "        name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}\",\n",
    "        config={\n",
    "            'model': type(model).__name__,\n",
    "            'dataset': 'DwarfRabbits-binary',\n",
    "            'batch_size': config['batch_size'],\n",
    "            'max_epochs': config['max_epochs'],\n",
    "            'learning_rate': config['learning_rate']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer with wandb logger, using early stopping callback\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config['max_epochs'], \n",
    "        default_root_dir='model/checkpoint/',\n",
    "        accelerator=\"auto\", \n",
    "        devices=\"auto\", \n",
    "        strategy=\"auto\",\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "        logger=wandb_logger)\n",
    "\n",
    "    # Training of the model\n",
    "    trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "    # Finish wandb\n",
    "    wandb.finish()\n",
    "\n",
    "    # Create a filename with date identifier\n",
    "    model_filename = f\"{config['wandb_experiment_name']}_{type(model).__name__}_{current_time}.ckpt\"\n",
    "\n",
    "    # Save the model's state_dict to the path specified in config\n",
    "    save_path = os.path.join(os.path.dirname(config['path_to_models']), model_filename)\n",
    "    trainer.save_checkpoint(save_path)\n",
    "    print(f\"Model checkpoint saved as {save_path}\")\n",
    "    \n",
    "    # Update config with the last trained model path\n",
    "    config['path_to_model'] = save_path\n",
    "    \n",
    "    print(f\"Completed training for {model_class.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95161133",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization with Optuna\n",
    "\n",
    "This section performs automated hyperparameter tuning using Optuna to find the optimal model configuration. The optimization process searches for hyperparameters that minimize validation loss across multiple trials, helping to improve model performance beyond manual tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576170ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization\n",
    "import datetime\n",
    "config['sweep_id'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "def objective(trial):\n",
    "    model = KaninchenModel                  # or another model's class, depending on your choice\n",
    "    trainer = CnnOptunaTrainer(\n",
    "        model=model,                        # Function to create the model\n",
    "        config=config,\n",
    "        normalize_mean=None, #[0.485, 0.456, 0.406], \n",
    "        normalize_std=None, #[0.229, 0.224, 0.225],\n",
    "        dataset_name=\"DwarfRabbits-binary\"\n",
    "    )\n",
    "    return trainer.run_training(trial)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")  # because we minimize val_loss\n",
    "\n",
    "# Set verbosity to WARNING to reduce output clutter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Start the hyperparameter optimization\n",
    "study.optimize(objective, n_trials=config['number_of_trials'])\n",
    "# study.optimize(objective, n_trials=3)\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best value (val_loss):\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378aefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94714cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a07eb",
   "metadata": {},
   "source": [
    "# Predict with the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import torch\n",
    "# # Load the saved model weights from the path specified in config\n",
    "\n",
    "# def predict_image(path, model):\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((150, 150)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "#     ])\n",
    "\n",
    "#     img = Image.open(path).convert('RGB')\n",
    "#     img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         pred = model(img)\n",
    "#         result = \"Dog\" if pred.item() > 0.5 else \"Cat\"\n",
    "#     print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738413b",
   "metadata": {},
   "source": [
    "### Loading and Evaluating the Trained Model\n",
    "\n",
    "The trained model is loaded from the checkpoint specified in the configuration. If the checkpoint exists, the model weights are restored and the model is set to evaluation mode. PyTorch Lightning's `Trainer` is then used to evaluate the model on the test dataset, providing a streamlined way to assess model performance after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = config['path_to_model']\n",
    "if model_path and os.path.exists(model_path):\n",
    "    #model = CatsDogsModel.load_from_checkpoint(model_path, map_location=device)\n",
    "    model = KaninchenModel.load_from_checkpoint(model_path, map_location=device)\n",
    "    print(f\"Loaded model weights from {model_path}\")\n",
    "else:\n",
    "    print(\"Model path not found or not specified in config.\")\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Pytorch Lightning's Trainer can be used to test the model\n",
    "trainer = Trainer()\n",
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDKI-Projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4845e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.datamodule import Animal_DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117666f9",
   "metadata": {},
   "source": [
    "### Loading Configuration\n",
    "\n",
    "In the following steps, we will load the configuration settings using the `load_configuration` function. The configuration is stored in the `config` variable which will be used throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74321032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC Name: DESKTOP-LUKAS\n",
      "Loaded configuration from config/config_default.yaml\n"
     ]
    }
   ],
   "source": [
    "from config.load_configuration import load_configuration\n",
    "config = load_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414378fc",
   "metadata": {},
   "source": [
    "### Setting Seeds for Reproducibility\n",
    "\n",
    "To ensure comparable and reproducible results, we set the random seed using the `seed_everything` function from PyTorch Lightning. This helps in achieving consistent behavior across multiple runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e10d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"   # disable oneDNN optimizations for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86df64",
   "metadata": {},
   "source": [
    "### Checking for GPU Devices\n",
    "\n",
    "In this step, we check for the availability of GPU devices and print the device currently being used by PyTorch. This ensures that the computations are performed on the most efficient hardware available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b717a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version:  2.7.0+cpu\n",
      "Using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Torch Version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "if device.type == 'cuda':\n",
    "    print('Cuda Version: ', torch.version.cuda)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177b86e",
   "metadata": {},
   "source": [
    "### Defining Transformations and Instantiating DataModule\n",
    "\n",
    "In this step, we will define the necessary data transformations and initialize the `Animal_DataModule` with the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df954014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define transformations here\n",
    "\n",
    "# Example for transformation\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # Resize images to match EfficientNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "])\n",
    "\n",
    "dl = Animal_DataModule(config['path_to_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c560cb9",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "In this step, we will define the model architecture and print its summary using the `ModelSummary` utility from PyTorch Lightning. This provides an overview of the model's layers, parameters, and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3442708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [1, 2]                    --\n",
       "├─Conv2d: 1-1                                 [1, 40, 150, 150]         (1,080)\n",
       "├─BatchNormAct2d: 1-2                         [1, 40, 150, 150]         80\n",
       "│    └─Identity: 2-1                          [1, 40, 150, 150]         --\n",
       "│    └─SiLU: 2-2                              [1, 40, 150, 150]         --\n",
       "├─Sequential: 1-3                             [1, 384, 10, 10]          --\n",
       "│    └─Sequential: 2-3                        [1, 24, 150, 150]         (3,504)\n",
       "│    └─Sequential: 2-4                        [1, 32, 75, 75]           (48,118)\n",
       "│    └─Sequential: 2-5                        [1, 48, 38, 38]           (110,912)\n",
       "│    └─Sequential: 2-6                        [1, 96, 19, 19]           (638,700)\n",
       "│    └─Sequential: 2-7                        [1, 136, 19, 19]          (1,387,760)\n",
       "│    └─Sequential: 2-8                        [1, 232, 10, 10]          (4,628,964)\n",
       "│    └─Sequential: 2-9                        [1, 384, 10, 10]          (3,284,218)\n",
       "├─Conv2d: 1-4                                 [1, 1536, 10, 10]         (589,824)\n",
       "├─BatchNormAct2d: 1-5                         [1, 1536, 10, 10]         3,072\n",
       "│    └─Identity: 2-10                         [1, 1536, 10, 10]         --\n",
       "│    └─SiLU: 2-11                             [1, 1536, 10, 10]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [1, 1536]                 --\n",
       "│    └─AdaptiveAvgPool2d: 2-12                [1, 1536, 1, 1]           --\n",
       "│    └─Flatten: 2-13                          [1, 1536]                 --\n",
       "├─Linear: 1-7                                 [1, 2]                    (3,074)\n",
       "===============================================================================================\n",
       "Total params: 10,699,306\n",
       "Trainable params: 0\n",
       "Non-trainable params: 10,699,306\n",
       "Total mult-adds (Units.GIGABYTES): 1.83\n",
       "===============================================================================================\n",
       "Input size (MB): 1.08\n",
       "Forward/backward pass size (MB): 190.64\n",
       "Params size (MB): 42.45\n",
       "Estimated Total Size (MB): 234.17\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model = timm.create_model(\n",
    "    'efficientnet_b3',      # Hardcoded for now\n",
    "    pretrained=True,\n",
    ")\n",
    "# Define number of classes and classifier\n",
    "num_classes = 1             # Hardcoded for now, Dwarf Rabbit OK/NOK output    \n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "# Freeze all layers except the classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier.requires_grad = True\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(1, 3, 300, 300), depth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b83af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Wandb logger\n",
    "wandb_config = {\n",
    "    'project_name': config['wandb_project_name'],\n",
    "    'experiment_name': config['wandb_experiment_name'],\n",
    "    'batch_size': config['batch_size'],\n",
    "    'max_epochs': config['max_epochs'],\n",
    "    'learning_rate': config['learning_rate'],\n",
    "}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=config['wandb_experiment_name'],\n",
    "    config=config\n",
    "    # save_dir=os.path.join(config['path_to_data'], 'logs')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer with wandb logger, using early stopping callback (https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/', #data_directory, \n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDKI-Projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4845e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryPrecisionRecallCurve\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "\n",
    "import datetime\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.datamodule import BinaryImageDataModule\n",
    "from training.hyperparameter_tuning import TLOptunaTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117666f9",
   "metadata": {},
   "source": [
    "### Loading Configuration\n",
    "\n",
    "In the following steps, we will load the configuration settings using the `load_configuration` function. The configuration is stored in the `config` variable which will be used throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74321032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC Name: DESKTOP-LUKAS\n",
      "Loaded configuration from config/config_lukas.yaml\n"
     ]
    }
   ],
   "source": [
    "from config.load_configuration import load_configuration\n",
    "config = load_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d537e99",
   "metadata": {},
   "source": [
    "### Logging in to Weights & Biases (wandb)\n",
    "\n",
    "Before starting any experiment tracking, ensure you are logged in to your Weights & Biases (wandb) account. This enables automatic logging of metrics, model checkpoints, and experiment configurations. The following code logs you in to wandb:\n",
    "\n",
    "```python\n",
    "wandb.login()\n",
    "```\n",
    "If you are running this for the first time, you may be prompted to enter your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bd2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-pelz\u001b[0m (\u001b[33mHKA-EKG-Signalverarbeitung\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Wandb logger\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414378fc",
   "metadata": {},
   "source": [
    "### Setting Seeds for Reproducibility\n",
    "\n",
    "To ensure comparable and reproducible results, we set the random seed using the `seed_everything` function from PyTorch Lightning. This helps in achieving consistent behavior across multiple runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e10d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"   # disable oneDNN optimizations for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86df64",
   "metadata": {},
   "source": [
    "### Checking for GPU Devices\n",
    "\n",
    "In this step, we check for the availability of GPU devices and print the device currently being used by PyTorch. This ensures that the computations are performed on the most efficient hardware available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b717a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version:  2.7.0+cu128\n",
      "Using device:  cuda\n",
      "Cuda Version:  12.8\n",
      "NVIDIA GeForce RTX 5060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Torch Version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "if device.type == 'cuda':\n",
    "    print('Cuda Version: ', torch.version.cuda)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464ce03",
   "metadata": {},
   "source": [
    "## Model definitions\n",
    "\n",
    "Now included in model_transferlearning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887cdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timm.list_models('*convnext*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6489689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getEfficientNetB4_model(amount_of_trainable_linear_layers=2):\n",
    "#     \"\"\"\n",
    "#     Function to get the EfficientNet B3 model with pretrained weights.\n",
    "#     Returns:\n",
    "#         model: A PyTorch model instance of EfficientNet B3.\n",
    "#     \"\"\"\n",
    "#     # Load the EfficientNet B3 model with pretrained weights\n",
    "#     model = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "    \n",
    "#     # Modify the classifier for binary classification\n",
    "#     num_classes = 1  # For binary classification (OK/NOK)\n",
    "#     if amount_of_trainable_linear_layers == 1:\n",
    "#         model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "#     elif amount_of_trainable_linear_layers == 2:\n",
    "#         # If two linear layers are trainable, we add an intermediate layer\n",
    "#         model.classifier = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(p=0.2),  # Add dropout for regularization\n",
    "#             torch.nn.Linear(model.classifier.in_features, 256),  # Intermediate layer\n",
    "#             torch.nn.ReLU(),  # Activation function\n",
    "#             torch.nn.Dropout(p=0.2),  # Another dropout layer\n",
    "#             torch.nn.Linear(256, num_classes)\n",
    "#         )\n",
    "    \n",
    "#     # Freeze all layers except the classifier\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.classifier.parameters():\n",
    "#         param.requires_grad = True\n",
    "    \n",
    "#     return model, \"TL_EfficientNetB4\"\n",
    "\n",
    "# def getResNet152D_model(amount_of_trainable_linear_layers=2):\n",
    "\n",
    "#     # Load the EfficientNet B3 model with pretrained weights\n",
    "#     model = timm.create_model('resnet152d', pretrained=True)\n",
    "    \n",
    "#     # Modify the classifier for binary classification\n",
    "#     num_classes = 1  # For binary classification (OK/NOK)\n",
    "#     if amount_of_trainable_linear_layers == 1:\n",
    "#         model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "#     elif amount_of_trainable_linear_layers == 2:\n",
    "#         # If two linear layers are trainable, we add an intermediate layer\n",
    "#         model.fc = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(p=0.2),                        # Add dropout for regularization\n",
    "#             torch.nn.Linear(model.fc.in_features, 256),     # Intermediate layer\n",
    "#             torch.nn.ReLU(),                                # Activation function\n",
    "#             torch.nn.Dropout(p=0.2),                        # Another dropout layer\n",
    "#             torch.nn.Linear(256, num_classes)\n",
    "#         )\n",
    "    \n",
    "#     # Freeze all layers except the classifier\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = True\n",
    "    \n",
    "#     return model, \"TL_ResNet50D\"\n",
    "\n",
    "# def getInceptionV4_model(amount_of_trainable_linear_layers=2):\n",
    "\n",
    "#     # Load the EfficientNet B3 model with pretrained weights\n",
    "#     model = timm.create_model('inception_v4', pretrained=True)\n",
    "    \n",
    "#     # Modify the classifier for binary classification\n",
    "#     num_classes = 1  # For binary classification (OK/NOK)\n",
    "#     if amount_of_trainable_linear_layers == 1:\n",
    "#         model.last_linear = torch.nn.Linear(model.last_linear.in_features, num_classes)\n",
    "#     elif amount_of_trainable_linear_layers == 2:\n",
    "#         model.last_linear = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(p=0.2),                                # Add dropout for regularization\n",
    "#             torch.nn.Linear(model.last_linear.in_features, 256),    # Intermediate layer\n",
    "#             torch.nn.ReLU(),                                        # Activation function\n",
    "#             torch.nn.Dropout(p=0.2),                                # Another dropout layer\n",
    "#             torch.nn.Linear(256, num_classes)\n",
    "#         )\n",
    "    \n",
    "#     # Freeze all layers except the classifier\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.last_linear.parameters():\n",
    "#         param.requires_grad = True\n",
    "    \n",
    "#     return model, \"TL_InceptionV4\"\n",
    "\n",
    "# def getConvNextV2_model(amount_of_trainable_linear_layers=2):\n",
    "\n",
    "#     # Load the EfficientNet B3 model with pretrained weights\n",
    "#     model = timm.create_model('convnextv2_base', pretrained=True)\n",
    "    \n",
    "#     # Modify the classifier for binary classification\n",
    "#     num_classes = 1  # For binary classification (OK/NOK)\n",
    "#     if amount_of_trainable_linear_layers == 1:\n",
    "#         model.head.fc = torch.nn.Linear(model.head.fc.in_features, num_classes)\n",
    "#     elif amount_of_trainable_linear_layers == 2:\n",
    "#         model.head.fc = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(p=0.2),                                # Add dropout for regularization\n",
    "#             torch.nn.Linear(model.head.fc.in_features, 256),    # Intermediate layer\n",
    "#             torch.nn.ReLU(),                                        # Activation function\n",
    "#             torch.nn.Dropout(p=0.2),                                # Another dropout layer\n",
    "#             torch.nn.Linear(256, num_classes)\n",
    "#         )\n",
    "    \n",
    "#     # Freeze all layers except the classifier\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.head.fc.parameters():\n",
    "#         param.requires_grad = True\n",
    "    \n",
    "#     return model, \"TL_ConvNextV2_base\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6daf14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model('convnextv2_base', pretrained=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff3cdd",
   "metadata": {},
   "source": [
    "### Transfer Learning with EfficientNet_B4\n",
    "\n",
    "In this step, we utilize the EfficientNet_B4 model for transfer learning. The model is pre-trained on ImageNet, and we adapt it to our specific task by modifying the classifier layer to match the number of output classes (`num_classes`). \n",
    "\n",
    "We freeze all layers except the classifier to retain the pre-trained features while allowing the classifier to learn task-specific features. The model summary provides an overview of the architecture and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30dde3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250611_173828-6oj5wdtm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/6oj5wdtm' target=\"_blank\">binaryClassification_CNN_TL_EfficientNetB4_img380_2025-06-11_17-38-28</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/6oj5wdtm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/6oj5wdtm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | EfficientNet      | 17.6 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "17.5 M    Non-trainable params\n",
      "17.6 M    Total params\n",
      "70.202    Total estimated model params size (MB)\n",
      "659       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0295c741639342e3a09101691be8e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73282a183ca94dfbb14c3542a4618d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1a8dc899cf4b639793fa20d3a9c053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae925d45885480298dbedef31b46091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbee15761b4d43e5823d9cecfd39e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ec204afb4c468b94d2350dc96c5de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b72f656be9f44e8942307f6a0476c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d968d50a13d44b2b372f9799241ea53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8841071e9144b5a4b07c763f48df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25f22f502fd40c1b904f0496cc99d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7828dd10f35b4131a24cdfaba7c3bd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7bca5bbcee405f96952156081ecd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d24aafbc70454ea7a807f5d8edf778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34824a76586d4839a456f8c305a51a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dc9f3c5ccf45b6a7a959e77267e800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28754a91bc154ea8afe733b49ca5d3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047423628239498384456ab4221ef16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f779e5d5f8f4defb5627ea2ccbeb455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f50e13ce3bc45e9ad8db3b5621da47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cf8ae290384cd99b35570ab7cde834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c087f2a611a48e194e575be40af7128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36a08bb02274fc4bff74e07cd15b00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60392be7cde4f58955cfe3f170113ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2744e321525e4b419ec49b346b056517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92c8bfcb38647b3a5cb92f8324d2944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>▆▅▆█▆▇▅▄▆▆▄▅▅▃▁▃▁▂▂▃▂▃▆▁▃▁▄▃▃▁▆▂▁▅▅▂▂▅▆▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▃▄▅▆▆▆▇▇▇██▇███▇█████▇</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▂▁▃▃▅▅▆▄▄▇▆▆▇▅▇▆▅▇▆█▆▆▅</td></tr><tr><td>val_recall</td><td>▁▄▄▅▅▆▆██▆█▇▆█▇▇█▇▇▆██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99634</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>train_acc</td><td>0.97891</td></tr><tr><td>train_loss</td><td>0.12584</td></tr><tr><td>trainer/global_step</td><td>6255</td></tr><tr><td>val_acc</td><td>0.96642</td></tr><tr><td>val_loss</td><td>0.08537</td></tr><tr><td>val_precision</td><td>0.95666</td></tr><tr><td>val_recall</td><td>0.97759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binaryClassification_CNN_TL_EfficientNetB4_img380_2025-06-11_17-38-28</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/6oj5wdtm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/6oj5wdtm</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a><br>Synced 5 W&B file(s), 72 media file(s), 96 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250611_173828-6oj5wdtm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.model_transferlearning import TL_EfficientNetB4\n",
    "import data.custom_transforms as custom_transforms\n",
    "\n",
    "# model = TransferLearningModule(model)\n",
    "model = TL_EfficientNetB4(amount_of_trainable_linear_layers=1)\n",
    "config['image_size'] = 380\n",
    "\n",
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'image_size': config['image_size']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/',\n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "dm = BinaryImageDataModule(\n",
    "    data_dir=config['path_to_split_aug_pics'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=6,\n",
    "    transform=v2.Compose([\n",
    "            custom_transforms.CenterCropSquare(),\n",
    "            v2.Resize((config['image_size'], config['image_size'])),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "trainer.save_checkpoint('trained_model/' + f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\" + '.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa4305",
   "metadata": {},
   "source": [
    "### Transfer Learning with ResNet152D\n",
    "\n",
    "In this step, we utilize the ResNet152D model for transfer learning. The model is pre-trained on ImageNet, and we adapt it to our specific task by modifying the classifier layer to match the number of output classes (`num_classes`). \n",
    "\n",
    "We freeze all layers except the classifier to retain the pre-trained features while allowing the classifier to learn task-specific features. The model summary provides an overview of the architecture and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a008ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250611_183416-qvt8zn0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/qvt8zn0n' target=\"_blank\">binaryClassification_CNN_TL_ResNet152D_img224_2025-06-11_18-34-16</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/qvt8zn0n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/qvt8zn0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29062811874480b9c2b7d8857d732c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad4720fcbf7411d82a82f5e257d4d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0a5edd044149fda6d0eac550e086ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2575574bfd7433abaaf6dc2fdd83047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683536f8e4754f45a0d549a1d1f79d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf720950fae4131b065d0138243b959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170e12ba38224c44a03a847d75f08e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32138e786084f80bba066092eef4844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d6e2af64fc490fb4573a17473e161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7484ed1d68134cee87022ba54830aa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ef51c90eaa4d8695fb58dd6b0adcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546e6a6a976440dd887e330a827b23b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ce4627618b4b1d8da688202e24c7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7723e1c7bb418c9a40df6f5a811336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc28d427a424717903acb9210b0ef7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5aa970d4c945bab90444716d0f9feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16aaa9f837f742ad98531777e411402c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d486026ced7843c59ae0d6ee8177ffeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a209775f740e8b82451e48c1b7c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e00c41144144f828cb976b475b1df34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaedf92c8e9459bb817dac9d7219683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9507af2932e4cab8e934def071eb135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9c3873b8794013a3056da7cbb0a6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df40031931974bdfbbacb53dbe796b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fe8b510cdb446e95812de551e06a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3316dac2bb8423887d0961075654fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a343ccb97e874eec801367340b96b90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b29b43fa1844b53ad3b24460e5ee353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df79ee00613a4ceea73f1c9881e8012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80ba991c0f74175a3f61d33bc0957b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf2617dac794b23a77dbfcd820faf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177b130f83be4ec2b4e60c84a8fc8355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d1a488bbbb4572bf05b0ab87dfc571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cfdbddd5e6429aaf2444494f723305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a82e14d45d940b396b07cc42fb2d327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇▇▇▇▇▇▇█▇▇███████▇█▇██▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇▇▇█▇▇█▇█▇████████████████</td></tr><tr><td>train_loss</td><td>▇█▅▄▅▂▅▂▂▃▂▂▂▂▂▂▂▄▂▃▂▂▁▂▁█▁▄▁▄▂▁▂▂▅▁▃▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▆▆▇▆▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▄▄▇▇▇▆█▅▆▆▇▇█▇▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇█▇</td></tr><tr><td>val_recall</td><td>▁▅▄▇▄▃▃█▁▇██▄▆▃▆▅▆▇▅▇▆▆▅▇▇▆▇▅▆▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99861</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>train_acc</td><td>0.99052</td></tr><tr><td>train_loss</td><td>0.0111</td></tr><tr><td>trainer/global_step</td><td>8975</td></tr><tr><td>val_acc</td><td>0.98119</td></tr><tr><td>val_loss</td><td>0.05149</td></tr><tr><td>val_precision</td><td>0.9803</td></tr><tr><td>val_recall</td><td>0.98239</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binaryClassification_CNN_TL_ResNet152D_img224_2025-06-11_18-34-16</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/qvt8zn0n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/qvt8zn0n</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a><br>Synced 5 W&B file(s), 102 media file(s), 136 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250611_183416-qvt8zn0n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.model_transferlearning import TL_ResNet152D\n",
    "import data.custom_transforms as custom_transforms\n",
    "\n",
    "# model = TransferLearningModule(model)\n",
    "model = TL_ResNet152D(amount_of_trainable_linear_layers=1)\n",
    "config['image_size'] = 224\n",
    "\n",
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'image_size': config['image_size']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/',\n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "dm = BinaryImageDataModule(\n",
    "    data_dir=config['path_to_split_aug_pics'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=6,\n",
    "    transform=v2.Compose([\n",
    "            custom_transforms.CenterCropSquare(),\n",
    "            v2.Resize((config['image_size'], config['image_size'])),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "trainer.save_checkpoint('trained_model/' + f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\" + '.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c1d84",
   "metadata": {},
   "source": [
    "### Transfer Learning with Inception V4\n",
    "\n",
    "In this step, we utilize the Inception V4 model for transfer learning. The model is pre-trained on ImageNet, and we adapt it to our specific task by modifying the classifier layer to match the number of output classes (`num_classes`). \n",
    "\n",
    "We freeze all layers except the classifier to retain the pre-trained features while allowing the classifier to learn task-specific features. The model summary provides an overview of the architecture and the number of trainable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d402b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250611_205404-s9a2vzef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/s9a2vzef' target=\"_blank\">binaryClassification_CNN_TL_InceptionV4_img299_2025-06-11_20-54-04</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/s9a2vzef' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/s9a2vzef</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | InceptionV4       | 41.1 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "41.1 M    Non-trainable params\n",
      "41.1 M    Total params\n",
      "164.577   Total estimated model params size (MB)\n",
      "836       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae51cb63afc497f988d8ed5b4c4e65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e690e71ceb84d718ba6783544580a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f5cc4f7e44c759116cca131f7e197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bd4e37d455445a8a3843472ce29727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40ad6a09604465986949e94631cace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e71095a21da41639926116c85792c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9f7b32ea6b461db5fea93021334ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f869ec79a74f488199c8d1cb706d5651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c598c7cb6642ee98cb7d7ce1883411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ce4240c4c2407cb59e7f31035952e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31491344f3c4af790f494abd2917f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fecbacb3f54bfcabbc480e5963f25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3fd4b9bfb04502a384d844a75ad114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1416f04a46a94a5598c519bb61a5692f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2df522f4cdd478ba132e87f04b780b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cb1136137e4fd7ac6d68ec9bece1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e23b0ecbc2c4f628601cf06eb134c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1086764c3b1944eba638a177a271ab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e076c8dd545043c4902be079dbd1f8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3ffb780be244f19f94e2459f94e59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2968663486429296c96063bd2ff925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e421db7788e74817860d5ff644a45fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c6eb95808b464aa3e9969d9b506ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9cd973de6544088454e6ba3beccbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871c9bad8a704b94a352a211f327f92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▇▇▇▇▇██▇████████▇██</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▄▃█▆▅▂▂▃▂▅▃▂▆▄▃▂▃▂▃▂▂▃▁▁▃▃▂▂▂▃▃▄▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇▇███▇█▇█▇███▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▃▄▃▅▆▂▅█▅▅▆▅▆▅▅▆▄▆▄▅▅</td></tr><tr><td>val_recall</td><td>▁▄▅▅▇▆▅█▆▅▇▇▆▇▆▇▇▆▇▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99529</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>train_acc</td><td>0.97563</td></tr><tr><td>train_loss</td><td>0.14376</td></tr><tr><td>trainer/global_step</td><td>6255</td></tr><tr><td>val_acc</td><td>0.9683</td></tr><tr><td>val_loss</td><td>0.08794</td></tr><tr><td>val_precision</td><td>0.96357</td></tr><tr><td>val_recall</td><td>0.97385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binaryClassification_CNN_TL_InceptionV4_img299_2025-06-11_20-54-04</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/s9a2vzef' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/s9a2vzef</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a><br>Synced 5 W&B file(s), 72 media file(s), 96 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250611_205404-s9a2vzef\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.model_transferlearning import TL_InceptionV4\n",
    "import data.custom_transforms as custom_transforms\n",
    "\n",
    "# model = TransferLearningModule(model)\n",
    "model = TL_InceptionV4(amount_of_trainable_linear_layers=1)\n",
    "config['image_size'] = 299\n",
    "\n",
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'image_size': config['image_size']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/',\n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "dm = BinaryImageDataModule(\n",
    "    data_dir=config['path_to_split_aug_pics'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=6,\n",
    "    transform=v2.Compose([\n",
    "            custom_transforms.CenterCropSquare(),\n",
    "            v2.Resize((config['image_size'], config['image_size'])),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "trainer.save_checkpoint('trained_model/' + f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\" + '.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0f7b0",
   "metadata": {},
   "source": [
    "### Transfer Learning with ConvNextV2\n",
    "\n",
    "In this step, we utilize the ConvNextV2 model for transfer learning. The model is pre-trained on ImageNet, and we adapt it to our specific task by modifying the classifier layer to match the number of output classes (`num_classes`). \n",
    "\n",
    "We freeze all layers except the classifier to retain the pre-trained features while allowing the classifier to learn task-specific features. The model summary provides an overview of the architecture and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ea9c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250614_174005-7l3uy4of</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/7l3uy4of' target=\"_blank\">binaryClassification_CNN_TL_ConvNextV2_img224_2025-06-14_17-40-05</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/7l3uy4of' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/7l3uy4of</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4c98117db2404c9ee4e96238aa118e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0414055f98684cf88a84af1779706067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a0823e3854a86954003fe55784f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e53fa407c24095aaaed7a7b7d197b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02c079a913c415184fa017ac304b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828258aada0049659e80d909cb0569a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f6b8dac63d4dd2a8729b622fea15e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66750e6d3b74085bf9fbaf5018a9acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6345b4e80fd40848754c184af7bf7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990b83135c864cea83b674c6736d406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c43ea2952674868a8e703a1610c3bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30da69d9d0d430aa643dacbab2f2387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9711b9610b6046419db77be3b3c56e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▇▆▇▆▇▁▂▂▁▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>▆▄▂▂▂█▃▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▅▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>val_acc</td><td>▄▁▂█▁▇▁▁▅▇▇</td></tr><tr><td>val_loss</td><td>▇▃▃▁▃▁▆█▆▆▅</td></tr><tr><td>val_precision</td><td>▁▄█▅▆▆▆▆▅▅▅</td></tr><tr><td>val_recall</td><td>▇▃▁█▁▆▁▁▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99976</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.99874</td></tr><tr><td>train_loss</td><td>0.00368</td></tr><tr><td>trainer/global_step</td><td>2991</td></tr><tr><td>val_acc</td><td>0.99382</td></tr><tr><td>val_loss</td><td>0.02083</td></tr><tr><td>val_precision</td><td>0.99518</td></tr><tr><td>val_recall</td><td>0.99253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binaryClassification_CNN_TL_ConvNextV2_img224_2025-06-14_17-40-05</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/7l3uy4of' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning/runs/7l3uy4of</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_TransferLearning</a><br>Synced 5 W&B file(s), 36 media file(s), 48 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250614_174005-7l3uy4of\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.model_transferlearning import TL_ConvNextV2\n",
    "import data.custom_transforms as custom_transforms\n",
    "\n",
    "# model = TransferLearningModule(model)\n",
    "model = TL_ConvNextV2(amount_of_trainable_linear_layers=1)\n",
    "config['image_size'] = 224\n",
    "\n",
    "# Initialize the Wandb logger\n",
    "# add time to the name of the experiment\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb_project_name'],\n",
    "    name=f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\",\n",
    "    config={\n",
    "        'model': type(model).__name__,\n",
    "        'dataset': 'DwarfRabbits-binary',\n",
    "        'batch_size': config['batch_size'],\n",
    "        'max_epochs': config['max_epochs'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'image_size': config['image_size']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize Trainer with wandb logger, using early stopping callback\n",
    "trainer = Trainer(\n",
    "    max_epochs=config['max_epochs'], \n",
    "    default_root_dir='model/checkpoint/',\n",
    "    accelerator=\"auto\", \n",
    "    devices=\"auto\", \n",
    "    strategy=\"auto\",\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='min')], \n",
    "    logger=wandb_logger)\n",
    "\n",
    "dm = BinaryImageDataModule(\n",
    "    data_dir=config['path_to_split_aug_pics'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=6,\n",
    "    transform=v2.Compose([\n",
    "            custom_transforms.CenterCropSquare(),\n",
    "            v2.Resize((config['image_size'], config['image_size'])),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Training of the model\n",
    "trainer.fit(model=model, datamodule=dm)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "trainer.save_checkpoint('trained_model/' + f\"{config['wandb_experiment_name']}_{type(model).__name__}_img{config['image_size']}_{current_time}\" + '.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005d275",
   "metadata": {},
   "source": [
    "### EfficientNet B4: Training and Logging with Weights & Biases including Hyper-Parameter Tuning\n",
    "\n",
    "In this step, we initialize the Weights & Biases (wandb) logger to track experiment metrics, hyperparameters, and model checkpoints. The logger is configured with project and experiment names, as well as key training parameters such as dataset, batch size, maximum epochs, and learning rate.\n",
    "\n",
    "We then set up the PyTorch Lightning `Trainer` with the wandb logger and an early stopping callback to monitor validation loss. The model is trained using the specified datamodule, and all relevant metrics are automatically logged to wandb for further analysis and visualization. After training, wandb logging is finalized to ensure all data is properly saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b648e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-02 14:50:50,658] A new study created in memory with name: no-name-d9e51de7-83c3-44ad-b606-3fae3ca32208\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250602_145051-mdzvuo72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/mdzvuo72' target=\"_blank\">TL_EfficientNetB3_cls1_bs128_img192_optAdamW_lr1e-04_wd1e-04_sch_StepLR_2025-06-02_14-50</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/mdzvuo72' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen/runs/mdzvuo72</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | EfficientNet      | 17.6 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "17.5 M    Non-trainable params\n",
      "17.6 M    Total params\n",
      "70.202    Total estimated model params size (MB)\n",
      "659       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "config['sweep_id'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "from models.model_transferlearning import getEfficientNetB4_model\n",
    "\n",
    "config['image_size'] = 300\n",
    "def objective(trial):\n",
    "    model_fct = getEfficientNetB4_model\n",
    "    trainer = TLOptunaTrainer(\n",
    "        model=model_fct,                        # Function to create the model\n",
    "        config=config,\n",
    "        normalize_mean=[0.485, 0.456, 0.406], \n",
    "        normalize_std=[0.229, 0.224, 0.225],\n",
    "        dataset_name=\"DwarfRabbits-binary\"\n",
    "    )\n",
    "    return trainer.run_training(trial)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")  # because we minimize val_loss\n",
    "\n",
    "# Set verbosity to WARNING to reduce output clutter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Start the hyperparameter optimization\n",
    "study.optimize(objective, n_trials=config['number_of_trials'])\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best value (val_loss):\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a47ec704",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m optuna.visualization.plot_optimization_history(\u001b[43mstudy\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74c6d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "precision (CategoricalDistribution): 0.00047476880075263773<extra></extra>",
          "optimizer (CategoricalDistribution): 0.006680395255010569<extra></extra>",
          "weight_decay (FloatDistribution): 0.009299763878048472<extra></extra>",
          "learning_rate (FloatDistribution): 0.01458148850999868<extra></extra>",
          "accumulate_grad_batches (CategoricalDistribution): 0.020725814023213503<extra></extra>",
          "scheduler (CategoricalDistribution): 0.0234693520224588<extra></extra>",
          "max_epochs (IntDistribution): 0.06974056553914731<extra></extra>",
          "model_classifier_layers (IntDistribution): 0.12342936474401241<extra></extra>",
          "batch_size (CategoricalDistribution): 0.24657858834920907<extra></extra>",
          "image_size (CategoricalDistribution): 0.4850198988781486<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "<0.01",
          "<0.01",
          "0.01",
          "0.02",
          "0.02",
          "0.07",
          "0.12",
          "0.25",
          "0.49"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.00047476880075263773,
          0.006680395255010569,
          0.009299763878048472,
          0.01458148850999868,
          0.020725814023213503,
          0.0234693520224588,
          0.06974056553914731,
          0.12342936474401241,
          0.24657858834920907,
          0.4850198988781486
         ],
         "y": [
          "precision",
          "optimizer",
          "weight_decay",
          "learning_rate",
          "accumulate_grad_batches",
          "scheduler",
          "max_epochs",
          "model_classifier_layers",
          "batch_size",
          "image_size"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398ae57",
   "metadata": {},
   "source": [
    "### ResNet152D: Training and Logging with Weights & Biases including Hyper-Parameter Tuning\n",
    "\n",
    "In this step, we initialize the Weights & Biases (wandb) logger to track experiment metrics, hyperparameters, and model checkpoints. The logger is configured with project and experiment names, as well as key training parameters such as dataset, batch size, maximum epochs, and learning rate.\n",
    "\n",
    "We then set up the PyTorch Lightning `Trainer` with the wandb logger and an early stopping callback to monitor validation loss. The model is trained using the specified datamodule, and all relevant metrics are automatically logged to wandb for further analysis and visualization. After training, wandb logging is finalized to ensure all data is properly saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e566d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 08:55:39,206] A new study created in memory with name: no-name-9d4522ad-ba85-4a74-b556-eb25f81f59a7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a581c8f03b9c4eb797674bc996078666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_085539-5irvsjaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5irvsjaa' target=\"_blank\">TL_ResNet50D_cls2_bs128_img192_optAdam_lr1e-04_wd3e-03_sch_None_2025-06-17_08-55</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5irvsjaa' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5irvsjaa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=27` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇█▇█████████████████</td></tr><tr><td>train_loss</td><td>█▆▄▅▅▃▃▄▃▃▄▃▃▂▂▂▂▃▃▂▂▂▃▂▂▂▂▂▁▂▃▂▂▃▃▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▃▄▅▆▆▇▇▇▇▇▇█▇▇▇▇█▇████████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▆▇▇</td></tr><tr><td>val_recall</td><td>▂▂▁▄▄▄▆▆▅▅▆▅▇▆▅▄▄▅▃▇█▆█▇█▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99758</td></tr><tr><td>epoch</td><td>26</td></tr><tr><td>train_acc</td><td>0.9781</td></tr><tr><td>train_loss</td><td>0.06637</td></tr><tr><td>trainer/global_step</td><td>917</td></tr><tr><td>val_acc</td><td>0.97474</td></tr><tr><td>val_loss</td><td>0.07259</td></tr><tr><td>val_precision</td><td>0.96941</td></tr><tr><td>val_recall</td><td>0.98079</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs128_img192_optAdam_lr1e-04_wd3e-03_sch_None_2025-06-17_08-55</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5irvsjaa' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5irvsjaa</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 84 media file(s), 112 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_085539-5irvsjaa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.07259383797645569\n",
      "[I 2025-06-17 09:22:07,435] Trial 0 finished with value: 0.07259383797645569 and parameters: {'batch_size': 128, 'image_size': 192, 'max_epochs': 27, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'Adam', 'learning_rate': 0.00012189772614581206, 'weight_decay': 0.0027910280630573945, 'scheduler': None, 'model_classifier_layers': 2}. Best is trial 0 with value: 0.07259383797645569.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_092208-s0f9xnim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s0f9xnim' target=\"_blank\">TL_ResNet50D_cls2_bs128_img192_optAdam_lr1e-03_wd2e-03_sch_CosineAnnealingLR_2025-06-17_09-22</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s0f9xnim' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s0f9xnim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▆▇▇▆▇▇████▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▆▇▇█▇█▇████</td></tr><tr><td>train_loss</td><td>█▇▃▃▄▃▆▂▂▃▂▃▂▃▁▃▁▆▂▆▄▅▃▃▅▃▅▁▁▁▁▃▁▂▃▂▂▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▆█▇▆▇████▇▆</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▁▁▁▁▁▃</td></tr><tr><td>val_precision</td><td>▁▄█▆▅█▇▇▆▄▅█</td></tr><tr><td>val_recall</td><td>▅▇▄▅▅▃▅▅▆█▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99729</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>train_acc</td><td>0.97868</td></tr><tr><td>train_loss</td><td>0.04908</td></tr><tr><td>trainer/global_step</td><td>407</td></tr><tr><td>val_acc</td><td>0.96857</td></tr><tr><td>val_loss</td><td>0.07769</td></tr><tr><td>val_precision</td><td>0.97927</td></tr><tr><td>val_recall</td><td>0.95784</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs128_img192_optAdam_lr1e-03_wd2e-03_sch_CosineAnnealingLR_2025-06-17_09-22</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s0f9xnim' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s0f9xnim</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 39 media file(s), 52 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_092208-s0f9xnim\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.07768524438142776\n",
      "[I 2025-06-17 09:34:18,426] Trial 1 finished with value: 0.07768524438142776 and parameters: {'batch_size': 128, 'image_size': 192, 'max_epochs': 37, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'Adam', 'learning_rate': 0.0009565195848008641, 'weight_decay': 0.0018987535093492264, 'scheduler': 'CosineAnnealingLR', 'model_classifier_layers': 2}. Best is trial 0 with value: 0.07259383797645569.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_093419-0o8pgl41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/0o8pgl41' target=\"_blank\">TL_ResNet50D_cls2_bs32_img224_optAdam_lr2e-03_wd6e-03_sch_None_2025-06-17_09-34</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/0o8pgl41' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/0o8pgl41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▅▄▁▄█▅█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇██</td></tr><tr><td>train_loss</td><td>▂▁▂▂▇▂▂▃▅▁▂█▁▃▂▂▁▃▄▂▄▃▂▂▄▄▁▃▂▂▄▃▁▃▁▂▃▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▆▃▁▆▆▇█</td></tr><tr><td>val_loss</td><td>▃▇█▁▂▂▁</td></tr><tr><td>val_precision</td><td>▂█▇▃▇▃▁</td></tr><tr><td>val_recall</td><td>▇▂▁▆▄▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99761</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>train_acc</td><td>0.95603</td></tr><tr><td>train_loss</td><td>0.32355</td></tr><tr><td>trainer/global_step</td><td>3807</td></tr><tr><td>val_acc</td><td>0.9734</td></tr><tr><td>val_loss</td><td>0.08053</td></tr><tr><td>val_precision</td><td>0.95677</td></tr><tr><td>val_recall</td><td>0.992</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs32_img224_optAdam_lr2e-03_wd6e-03_sch_None_2025-06-17_09-34</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/0o8pgl41' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/0o8pgl41</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 24 media file(s), 32 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_093419-0o8pgl41\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.08053471148014069\n",
      "[I 2025-06-17 09:42:47,277] Trial 2 finished with value: 0.08053471148014069 and parameters: {'batch_size': 32, 'image_size': 224, 'max_epochs': 29, 'accumulate_grad_batches': 1, 'precision': 32, 'optimizer': 'Adam', 'learning_rate': 0.0021456338373115518, 'weight_decay': 0.005994138431012119, 'scheduler': None, 'model_classifier_layers': 2}. Best is trial 0 with value: 0.07259383797645569.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_094248-xt5phyk3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/xt5phyk3' target=\"_blank\">TL_ResNet50D_cls1_bs32_img256_optSGD_lr4e-04_wd5e-06_sch_CosineAnnealingLR_2025-06-17_09-42</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/xt5phyk3' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/xt5phyk3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▇▆▇▇▇▇▇█▇██▇▇██████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train_acc</td><td>▁▇▇████████████████████</td></tr><tr><td>train_loss</td><td>█▇▅▄▄▄▃▃▃▄▄▃▃▂▂▅▃▄▃▂▄▃▂▃▂▁▁▂▃▃▂▂▂▂▂▁▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇██▇▇█</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▅▅▆▇▇▇█▇▇▇█▇▇████▇▇██▇</td></tr><tr><td>val_recall</td><td>█▄▇▅▁▃▄▁▄▆▇▅▅▆▇▃▅▄▇▇▂▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9933</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>train_acc</td><td>0.95029</td></tr><tr><td>train_loss</td><td>0.22288</td></tr><tr><td>trainer/global_step</td><td>3127</td></tr><tr><td>val_acc</td><td>0.95594</td></tr><tr><td>val_loss</td><td>0.20566</td></tr><tr><td>val_precision</td><td>0.94439</td></tr><tr><td>val_recall</td><td>0.96958</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls1_bs32_img256_optSGD_lr4e-04_wd5e-06_sch_CosineAnnealingLR_2025-06-17_09-42</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/xt5phyk3' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/xt5phyk3</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 72 media file(s), 96 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_094248-xt5phyk3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.20566357672214508\n",
      "[I 2025-06-17 10:14:52,546] Trial 3 finished with value: 0.20566357672214508 and parameters: {'batch_size': 32, 'image_size': 256, 'max_epochs': 25, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'SGD', 'learning_rate': 0.0003695881069032979, 'weight_decay': 4.6204557807909375e-06, 'scheduler': 'CosineAnnealingLR', 'model_classifier_layers': 1}. Best is trial 0 with value: 0.07259383797645569.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_101453-8gab7oy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8gab7oy8' target=\"_blank\">TL_ResNet50D_cls2_bs32_img256_optAdamW_lr2e-04_wd7e-04_sch_CosineAnnealingLR_2025-06-17_10-14</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8gab7oy8' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8gab7oy8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇█▇▇▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇████████████</td></tr><tr><td>train_loss</td><td>█▄▂▃▂▂▁▂▃▁▂▁▂▁▁▁▂▂▂▁▂▁▂▂▁▂▁▁▁▁▁▆▂▁▂▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▅▃▆▆▆▇▇▇▇█▇▆▇▇██▇█</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▆▅▅▆▆▅▆▅▇▅█▆▅▆▇▇▆</td></tr><tr><td>val_recall</td><td>▅█▁▅▆▅▆▇▆▇▆█▂▆█▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99816</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>train_acc</td><td>0.97931</td></tr><tr><td>train_loss</td><td>0.01327</td></tr><tr><td>trainer/global_step</td><td>2583</td></tr><tr><td>val_acc</td><td>0.9777</td></tr><tr><td>val_loss</td><td>0.05482</td></tr><tr><td>val_precision</td><td>0.97913</td></tr><tr><td>val_recall</td><td>0.97652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs32_img256_optAdamW_lr2e-04_wd7e-04_sch_CosineAnnealingLR_2025-06-17_10-14</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8gab7oy8' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8gab7oy8</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 60 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_101453-8gab7oy8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.054816488176584244\n",
      "[I 2025-06-17 10:42:36,998] Trial 4 finished with value: 0.054816488176584244 and parameters: {'batch_size': 32, 'image_size': 256, 'max_epochs': 30, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.0001678151215708893, 'weight_decay': 0.0007004815451423014, 'scheduler': 'CosineAnnealingLR', 'model_classifier_layers': 2}. Best is trial 4 with value: 0.054816488176584244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_104238-qry7um6j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/qry7um6j' target=\"_blank\">TL_ResNet50D_cls1_bs128_img224_optAdamW_lr6e-04_wd2e-06_sch_None_2025-06-17_10-42</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/qry7um6j' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/qry7um6j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=39` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▄▄▃▂▂▂▂▁▂▂▁▁▁▂▂▂▁▁▁▁▂▁▂▂▂▁▁▁▂▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>val_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▃▅▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█████▇██▇██▇███</td></tr><tr><td>val_recall</td><td>▅▅▂▃▁▄▄▅▅▅▆▄▆▆▆▅▇▆▅▅▄▅▆▆▄▆▅▆▆█▆▇█▇▇█▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99788</td></tr><tr><td>epoch</td><td>38</td></tr><tr><td>train_acc</td><td>0.98126</td></tr><tr><td>train_loss</td><td>0.05279</td></tr><tr><td>trainer/global_step</td><td>1325</td></tr><tr><td>val_acc</td><td>0.97636</td></tr><tr><td>val_loss</td><td>0.0712</td></tr><tr><td>val_precision</td><td>0.97551</td></tr><tr><td>val_recall</td><td>0.97759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls1_bs128_img224_optAdamW_lr6e-04_wd2e-06_sch_None_2025-06-17_10-42</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/qry7um6j' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/qry7um6j</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 120 media file(s), 160 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_104238-qry7um6j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.07120317220687866\n",
      "[I 2025-06-17 11:30:50,240] Trial 5 finished with value: 0.07120317220687866 and parameters: {'batch_size': 128, 'image_size': 224, 'max_epochs': 39, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.0005737546135444124, 'weight_decay': 2.299636751048457e-06, 'scheduler': None, 'model_classifier_layers': 1}. Best is trial 4 with value: 0.054816488176584244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_113051-obyi6u24</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/obyi6u24' target=\"_blank\">TL_ResNet50D_cls1_bs128_img224_optAdam_lr3e-04_wd4e-03_sch_StepLR_2025-06-17_11-30</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/obyi6u24' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/obyi6u24</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇██████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▃▃▃▃▃▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▁▁▁▂▂▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▇▇▇▇▇▇█▇▇█████████████████</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▅▇▆▇▇▇▇▇▇██▇▇███▇███▇█▇███▇██</td></tr><tr><td>val_recall</td><td>▅█▃▁▅▄▅▅▄▆▅▅▅▅▆▅▆▅▅▆▅▅▆▆▆▅▅▅▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9952</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>train_acc</td><td>0.96379</td></tr><tr><td>train_loss</td><td>0.12809</td></tr><tr><td>trainer/global_step</td><td>1053</td></tr><tr><td>val_acc</td><td>0.96265</td></tr><tr><td>val_loss</td><td>0.1322</td></tr><tr><td>val_precision</td><td>0.95443</td></tr><tr><td>val_recall</td><td>0.97225</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls1_bs128_img224_optAdam_lr3e-04_wd4e-03_sch_StepLR_2025-06-17_11-30</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/obyi6u24' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/obyi6u24</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 96 media file(s), 128 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_113051-obyi6u24\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.13220319151878357\n",
      "[I 2025-06-17 12:08:39,487] Trial 6 finished with value: 0.13220319151878357 and parameters: {'batch_size': 128, 'image_size': 224, 'max_epochs': 31, 'accumulate_grad_batches': 4, 'precision': 32, 'optimizer': 'Adam', 'learning_rate': 0.0003032624724982768, 'weight_decay': 0.003502447608580323, 'scheduler': 'StepLR', 'model_classifier_layers': 1}. Best is trial 4 with value: 0.054816488176584244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_120840-d0hqhdu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/d0hqhdu2' target=\"_blank\">TL_ResNet50D_cls1_bs32_img192_optAdamW_lr7e-04_wd3e-04_sch_StepLR_2025-06-17_12-08</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/d0hqhdu2' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/d0hqhdu2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>▄▄▅▄▇▃█▅▂▆▃▃▄▃▄▅▂▅▆▃▃▁▄▄▆▃▃▂▁▁▂▄▃▂▃▅▃▄▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▄▄▆▇▆█▇▇██▇█</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▃▅▆▅▇▇▆▇▆▆█▆</td></tr><tr><td>val_recall</td><td>▂▄▁▅▇▄▆▇▅██▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9978</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>train_acc</td><td>0.98</td></tr><tr><td>train_loss</td><td>0.04181</td></tr><tr><td>trainer/global_step</td><td>7071</td></tr><tr><td>val_acc</td><td>0.97663</td></tr><tr><td>val_loss</td><td>0.06417</td></tr><tr><td>val_precision</td><td>0.9725</td></tr><tr><td>val_recall</td><td>0.98132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls1_bs32_img192_optAdamW_lr7e-04_wd3e-04_sch_StepLR_2025-06-17_12-08</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/d0hqhdu2' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/d0hqhdu2</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 42 media file(s), 56 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_120840-d0hqhdu2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.06417486071586609\n",
      "[I 2025-06-17 12:17:16,831] Trial 7 finished with value: 0.06417486071586609 and parameters: {'batch_size': 32, 'image_size': 192, 'max_epochs': 38, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.0007320513354907748, 'weight_decay': 0.0002698781219479083, 'scheduler': 'StepLR', 'model_classifier_layers': 1}. Best is trial 4 with value: 0.054816488176584244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_121717-dabb914f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/dabb914f' target=\"_blank\">TL_ResNet50D_cls2_bs32_img224_optAdam_lr2e-04_wd6e-04_sch_CosineAnnealingLR_2025-06-17_12-17</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/dabb914f' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/dabb914f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▅███▆▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇▇█▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▂▃▁▅▂▁▁▅▂▃▁▁▂▂▃▁▃▁▃▁▂▁▁▂▁▁▂▂▃▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>val_acc</td><td>▅▁▆████▅</td></tr><tr><td>val_loss</td><td>▆█▃▂▁▁▁▄</td></tr><tr><td>val_precision</td><td>▃▇▄▇▅▁▂█</td></tr><tr><td>val_recall</td><td>▅▁▆▅▇██▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99854</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_acc</td><td>0.97454</td></tr><tr><td>train_loss</td><td>0.1019</td></tr><tr><td>trainer/global_step</td><td>4351</td></tr><tr><td>val_acc</td><td>0.97071</td></tr><tr><td>val_loss</td><td>0.0663</td></tr><tr><td>val_precision</td><td>0.99164</td></tr><tr><td>val_recall</td><td>0.94984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs32_img224_optAdam_lr2e-04_wd6e-04_sch_CosineAnnealingLR_2025-06-17_12-17</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/dabb914f' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/dabb914f</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 27 media file(s), 36 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_121717-dabb914f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.066299669444561\n",
      "[I 2025-06-17 12:23:35,139] Trial 8 finished with value: 0.066299669444561 and parameters: {'batch_size': 32, 'image_size': 224, 'max_epochs': 39, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'Adam', 'learning_rate': 0.0002366905301267228, 'weight_decay': 0.0006490140311669706, 'scheduler': 'CosineAnnealingLR', 'model_classifier_layers': 2}. Best is trial 4 with value: 0.054816488176584244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_122335-q00h9nr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/q00h9nr2' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-04_wd5e-04_sch_StepLR_2025-06-17_12-23</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/q00h9nr2' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/q00h9nr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=28` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▅▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇██▇████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▆▂▂▂▂█▂█▅▄▂▁▅▂▂▅▅▂▅▂▄▂▃▅▃▁▂▁▃▁▁▁▃▁▁▁▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇████</td></tr><tr><td>val_acc</td><td>▁▃▅▃▆▇▆▆▆▆▆▆▆▆▆▆▇▇▇█▇▇█▇█▇██</td></tr><tr><td>val_loss</td><td>█▅▄▅▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>val_precision</td><td>▂▅▅█▂▅▆▆▂▄▅▃▄▁▅▁▅▅▆▆▆█▆▅▅▅▅▆</td></tr><tr><td>val_recall</td><td>▂▃▅▁▇▆▅▅▇▆▆▇▇█▆█▇▇▆▇▆▅▆▆▇▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99871</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>train_acc</td><td>0.98994</td></tr><tr><td>train_loss</td><td>0.0145</td></tr><tr><td>trainer/global_step</td><td>7615</td></tr><tr><td>val_acc</td><td>0.98119</td></tr><tr><td>val_loss</td><td>0.04593</td></tr><tr><td>val_precision</td><td>0.97979</td></tr><tr><td>val_recall</td><td>0.98292</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-04_wd5e-04_sch_StepLR_2025-06-17_12-23</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/q00h9nr2' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/q00h9nr2</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 87 media file(s), 116 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_122335-q00h9nr2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.045927390456199646\n",
      "[I 2025-06-17 13:05:43,926] Trial 9 finished with value: 0.045927390456199646 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 28, 'accumulate_grad_batches': 1, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.00020314219398951655, 'weight_decay': 0.0005163996785034759, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 9 with value: 0.045927390456199646.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_130544-8t0zltnr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8t0zltnr' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optSGD_lr9e-03_wd4e-05_sch_StepLR_2025-06-17_13-05</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8t0zltnr' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8t0zltnr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▅▆▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▇▃▂▂▂▂▁▂▃▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▂▃▁▂▃▂▂▁▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>val_acc</td><td>▁▅▅▇▇▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▃▆▆▇▇▆███▆</td></tr><tr><td>val_recall</td><td>▅█▁▆▄▄▆▄▂▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9978</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.98144</td></tr><tr><td>train_loss</td><td>0.02536</td></tr><tr><td>trainer/global_step</td><td>1495</td></tr><tr><td>val_acc</td><td>0.97636</td></tr><tr><td>val_loss</td><td>0.05928</td></tr><tr><td>val_precision</td><td>0.9745</td></tr><tr><td>val_recall</td><td>0.97866</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optSGD_lr9e-03_wd4e-05_sch_StepLR_2025-06-17_13-05</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8t0zltnr' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8t0zltnr</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 36 media file(s), 48 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_130544-8t0zltnr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.05928408354520798\n",
      "[I 2025-06-17 13:16:52,215] Trial 10 finished with value: 0.05928408354520798 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 21, 'accumulate_grad_batches': 2, 'precision': '16-mixed', 'optimizer': 'SGD', 'learning_rate': 0.009296576991579793, 'weight_decay': 3.6669861314443464e-05, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 9 with value: 0.045927390456199646.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_131653-mh1kdia9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mh1kdia9' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr1e-04_wd5e-05_sch_CosineAnnealingLR_2025-06-17_13-16</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mh1kdia9' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mh1kdia9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=33` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇▇▇▇▇▇█▇▇▇▇███████████████▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇█▇▇█████▇████████████</td></tr><tr><td>train_loss</td><td>▇▄▄█▃▁▅▃▃▄▂▄▃▂▄▆▆▃▆▁▅▃▂▂▁▂▃▃▁▂▂▁▃▃▂▃▄▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██████▇█▇█████▇</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▅▄▅▇▆▇▆█▆▇▇█▇▇▇▆█▇▇▆▇█▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>val_recall</td><td>▃▂▆▆▃▇▄▆▁█▆▆▁▅▅▅▆▂▄▅█▆▂▅▃▆▆▅▄█▆▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99776</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>train_acc</td><td>0.98397</td></tr><tr><td>train_loss</td><td>0.03278</td></tr><tr><td>trainer/global_step</td><td>4487</td></tr><tr><td>val_acc</td><td>0.97582</td></tr><tr><td>val_loss</td><td>0.06057</td></tr><tr><td>val_precision</td><td>0.97701</td></tr><tr><td>val_recall</td><td>0.97492</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr1e-04_wd5e-05_sch_CosineAnnealingLR_2025-06-17_13-16</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mh1kdia9' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mh1kdia9</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 102 media file(s), 136 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_131653-mh1kdia9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.06056899204850197\n",
      "[I 2025-06-17 14:06:21,938] Trial 11 finished with value: 0.06056899204850197 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 33, 'accumulate_grad_batches': 2, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.00010820441737224754, 'weight_decay': 4.916036970711429e-05, 'scheduler': 'CosineAnnealingLR', 'model_classifier_layers': 2}. Best is trial 9 with value: 0.045927390456199646.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_140622-zvorqgtx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zvorqgtx' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-03_wd2e-04_sch_StepLR_2025-06-17_14-06</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zvorqgtx' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zvorqgtx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▅▅▆▆▇▇▇▇█▇██</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▄▆█▅▂▁▂▃▂▃▂▃▁▃▂▁▂▃▂▂▂▅▁▁▁▂▂▂▁▁▁▂▁▁▂▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▁▄▅▅▅▃▆▆▅█▇█▇</td></tr><tr><td>val_loss</td><td>██▅▅▄▃▅▄▃▄▁▂▂▂</td></tr><tr><td>val_precision</td><td>▅▁▃▄▇▅██▅▄▇▆▇▆</td></tr><tr><td>val_recall</td><td>▂▇▇█▄▇▁▄▇█▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9993</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>train_acc</td><td>0.99707</td></tr><tr><td>train_loss</td><td>0.00303</td></tr><tr><td>trainer/global_step</td><td>3807</td></tr><tr><td>val_acc</td><td>0.98603</td></tr><tr><td>val_loss</td><td>0.03661</td></tr><tr><td>val_precision</td><td>0.98561</td></tr><tr><td>val_recall</td><td>0.98666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-03_wd2e-04_sch_StepLR_2025-06-17_14-06</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zvorqgtx' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zvorqgtx</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 45 media file(s), 60 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_140622-zvorqgtx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.03660617768764496\n",
      "[I 2025-06-17 14:28:26,610] Trial 12 finished with value: 0.03660617768764496 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 24, 'accumulate_grad_batches': 1, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.0024603367683237068, 'weight_decay': 0.00016334996012291853, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_142827-8qjihd3q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8qjihd3q' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr3e-03_wd2e-05_sch_StepLR_2025-06-17_14-28</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8qjihd3q' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8qjihd3q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▂▆▇█▇▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇███</td></tr><tr><td>train_loss</td><td>▃▄▁█▆▂▁▂▄▂▂▂▁▂▂▂▃▁▁▂▁▁▁▂▂▂▁▂▁▂▂▁▁▁▁▂▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▅▄▁▇██▇▇</td></tr><tr><td>val_loss</td><td>▅▃▅█▂▁▁▃▂</td></tr><tr><td>val_precision</td><td>▄▂▅█▇▇▂▁▂</td></tr><tr><td>val_recall</td><td>▄▆▄▁▅▅██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99846</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_acc</td><td>0.98994</td></tr><tr><td>train_loss</td><td>0.07582</td></tr><tr><td>trainer/global_step</td><td>2447</td></tr><tr><td>val_acc</td><td>0.98039</td></tr><tr><td>val_loss</td><td>0.05339</td></tr><tr><td>val_precision</td><td>0.9732</td></tr><tr><td>val_recall</td><td>0.98826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr3e-03_wd2e-05_sch_StepLR_2025-06-17_14-28</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8qjihd3q' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/8qjihd3q</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 30 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_142827-8qjihd3q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.05338548123836517\n",
      "[I 2025-06-17 14:42:27,238] Trial 13 finished with value: 0.05338548123836517 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 23, 'accumulate_grad_batches': 1, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.002524049620616861, 'weight_decay': 1.878490876877129e-05, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_144228-4gozq4ie</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/4gozq4ie' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-03_wd2e-04_sch_StepLR_2025-06-17_14-42</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/4gozq4ie' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/4gozq4ie</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▆▇██▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇███</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇██</td></tr><tr><td>train_loss</td><td>▄▇▇█▃▅▁▃▃▄▃▇▃▃▂▁▅▅▂▂▅▄▃▁▁▄▃▂▁▂▂▁▂▃▂▁▁▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▄▅▇██▇█▇</td></tr><tr><td>val_loss</td><td>█▅▄▂▁▁▂▁▁</td></tr><tr><td>val_precision</td><td>▁▄█▆▇▇▇▇▆</td></tr><tr><td>val_recall</td><td>█▇▁▇▇▇▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99902</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_acc</td><td>0.99167</td></tr><tr><td>train_loss</td><td>0.04661</td></tr><tr><td>trainer/global_step</td><td>2447</td></tr><tr><td>val_acc</td><td>0.98388</td></tr><tr><td>val_loss</td><td>0.04057</td></tr><tr><td>val_precision</td><td>0.98245</td></tr><tr><td>val_recall</td><td>0.98559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr2e-03_wd2e-04_sch_StepLR_2025-06-17_14-42</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/4gozq4ie' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/4gozq4ie</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 30 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_144228-4gozq4ie\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.04057195037603378\n",
      "[I 2025-06-17 14:51:42,868] Trial 14 finished with value: 0.04057195037603378 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 25, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.0021751118973779354, 'weight_decay': 0.00019175316281041914, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_145143-zurgbt3a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zurgbt3a' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr3e-03_wd1e-04_sch_StepLR_2025-06-17_14-51</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zurgbt3a' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zurgbt3a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▇▆▆▇▃██</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇████</td></tr><tr><td>train_loss</td><td>▃▄▄▄▆▃█▂▃▂▂▆▄▄▃▂▂▁▂▂▂▂▂▃▁▁▁▅▄▁▃▁▄▁▂▁▂▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▆▆▇▆▇█▁██</td></tr><tr><td>val_loss</td><td>▃▃▂▃▁▁█▁▁</td></tr><tr><td>val_precision</td><td>▆▇█▁▄▆█▇▅</td></tr><tr><td>val_recall</td><td>▆▅▆██▇▁▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99894</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_acc</td><td>0.98948</td></tr><tr><td>train_loss</td><td>0.02217</td></tr><tr><td>trainer/global_step</td><td>2447</td></tr><tr><td>val_acc</td><td>0.98227</td></tr><tr><td>val_loss</td><td>0.04455</td></tr><tr><td>val_precision</td><td>0.97983</td></tr><tr><td>val_recall</td><td>0.98506</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr3e-03_wd1e-04_sch_StepLR_2025-06-17_14-51</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zurgbt3a' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/zurgbt3a</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 30 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_145143-zurgbt3a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.04454837366938591\n",
      "[I 2025-06-17 15:00:59,475] Trial 15 finished with value: 0.04454837366938591 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 20, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.0027486796049765515, 'weight_decay': 0.00014148460817811617, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_150100-9isf38ug</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9isf38ug' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr6e-03_wd1e-05_sch_StepLR_2025-06-17_15-01</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9isf38ug' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9isf38ug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅███▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████████</td></tr><tr><td>train_acc</td><td>▁▆▇▇███</td></tr><tr><td>train_loss</td><td>▃▃▃▃█▂▄▃▃▃▃▁▁▁▅▂█▁▃▃▁▁▂▁▄▆▁▃▂▃▁▂▁▂▁▁▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▅▅█▁▆▆</td></tr><tr><td>val_loss</td><td>▅▄▅▁█▃▇</td></tr><tr><td>val_precision</td><td>▆▅██▁█▅</td></tr><tr><td>val_recall</td><td>▃▆▁▅█▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99793</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>train_acc</td><td>0.98695</td></tr><tr><td>train_loss</td><td>0.01892</td></tr><tr><td>trainer/global_step</td><td>1903</td></tr><tr><td>val_acc</td><td>0.97985</td></tr><tr><td>val_loss</td><td>0.0736</td></tr><tr><td>val_precision</td><td>0.9707</td></tr><tr><td>val_recall</td><td>0.98986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr6e-03_wd1e-05_sch_StepLR_2025-06-17_15-01</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9isf38ug' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9isf38ug</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 24 media file(s), 32 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_150100-9isf38ug\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.07360348105430603\n",
      "[I 2025-06-17 15:08:21,672] Trial 16 finished with value: 0.07360348105430603 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 25, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.0063133929716765015, 'weight_decay': 1.3936275782879152e-05, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_150822-6ragbefm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/6ragbefm' target=\"_blank\">TL_ResNet50D_cls1_bs64_img256_optSGD_lr2e-03_wd1e-04_sch_StepLR_2025-06-17_15-08</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/6ragbefm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/6ragbefm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.2 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.660   Total estimated model params size (MB)\n",
      "642       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▄▅▅▇▆▆▇▇█▇▇▇█████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▇▅▄▄▃▄▄▂▅▃▄▃▃▃▃▁▆▃▁▅▂▂▃▂▄▃▂▂▃▂▂▁▁▁▂▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▃▄▄▆▇▇▆▇▇▇▇▇▇▇▇█▇▇███▇</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>val_recall</td><td>▁▂▃▄▅██▆▆█▆▆▅▅▇▅█▆▅▇▆▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99647</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>train_acc</td><td>0.97374</td></tr><tr><td>train_loss</td><td>0.04743</td></tr><tr><td>trainer/global_step</td><td>6255</td></tr><tr><td>val_acc</td><td>0.96749</td></tr><tr><td>val_loss</td><td>0.09317</td></tr><tr><td>val_precision</td><td>0.96747</td></tr><tr><td>val_recall</td><td>0.96798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls1_bs64_img256_optSGD_lr2e-03_wd1e-04_sch_StepLR_2025-06-17_15-08</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/6ragbefm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/6ragbefm</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 72 media file(s), 96 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_150822-6ragbefm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.09316893666982651\n",
      "[I 2025-06-17 15:31:01,184] Trial 17 finished with value: 0.09316893666982651 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 23, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'SGD', 'learning_rate': 0.0017377238572584398, 'weight_decay': 0.0001219427222839875, 'scheduler': 'StepLR', 'model_classifier_layers': 1}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_153102-5n9yrv51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5n9yrv51' target=\"_blank\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr4e-03_wd6e-05_sch_StepLR_2025-06-17_15-31</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5n9yrv51' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5n9yrv51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▂▅▆▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▆▇▂▄▄▂▂▇▁▃▅▂▁▂▂▁▁▇▁▁▂▁▂▁▁▃▁▂▃▁▁▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>val_acc</td><td>▁▁▅▆▅▆▇▇▇██▆█</td></tr><tr><td>val_loss</td><td>▇█▄▃▄▃▂▂▂▁▁▄▁</td></tr><tr><td>val_precision</td><td>▆▁▅▆▄▇▆▆▆▆▆█▆</td></tr><tr><td>val_recall</td><td>▁█▆▆█▅▇▆▇▇▇▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99915</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>train_acc</td><td>0.99402</td></tr><tr><td>train_loss</td><td>0.00209</td></tr><tr><td>trainer/global_step</td><td>1767</td></tr><tr><td>val_acc</td><td>0.98549</td></tr><tr><td>val_loss</td><td>0.03849</td></tr><tr><td>val_precision</td><td>0.98199</td></tr><tr><td>val_recall</td><td>0.98933</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img256_optAdamW_lr4e-03_wd6e-05_sch_StepLR_2025-06-17_15-31</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5n9yrv51' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/5n9yrv51</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 42 media file(s), 56 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_153102-5n9yrv51\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.03849393501877785\n",
      "[I 2025-06-17 15:43:59,922] Trial 18 finished with value: 0.03849393501877785 and parameters: {'batch_size': 64, 'image_size': 256, 'max_epochs': 34, 'accumulate_grad_batches': 2, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.00423891290896787, 'weight_decay': 5.9666017665336866e-05, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_154400-1wt0f394</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/1wt0f394' target=\"_blank\">TL_ResNet50D_cls2_bs64_img192_optAdamW_lr5e-03_wd7e-06_sch_StepLR_2025-06-17_15-44</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/1wt0f394' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/1wt0f394</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ResNet            | 58.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "58.2 M    Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.751   Total estimated model params size (MB)\n",
      "647       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▃▇▇▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇████</td></tr><tr><td>train_loss</td><td>█▄▄▅▅▄▄▃▂▃▃▇▁▄▃▃▂▃▃▃▁▆▂▃▂▄▂▁▂▁▁▁▁▁▂▁▁▁▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>val_acc</td><td>▁▄▁▆▅▇▆█▇</td></tr><tr><td>val_loss</td><td>▅▃█▁▄▁▃▁▁</td></tr><tr><td>val_precision</td><td>▄▇▁▇▄▇█▇▆</td></tr><tr><td>val_recall</td><td>▂▁█▃█▃▁▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99844</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_acc</td><td>0.98885</td></tr><tr><td>train_loss</td><td>0.18997</td></tr><tr><td>trainer/global_step</td><td>1223</td></tr><tr><td>val_acc</td><td>0.98039</td></tr><tr><td>val_loss</td><td>0.05389</td></tr><tr><td>val_precision</td><td>0.96974</td></tr><tr><td>val_recall</td><td>0.992</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ResNet50D_cls2_bs64_img192_optAdamW_lr5e-03_wd7e-06_sch_StepLR_2025-06-17_15-44</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/1wt0f394' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/1wt0f394</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 30 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_154400-1wt0f394\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.05388827994465828\n",
      "[I 2025-06-17 15:49:57,531] Trial 19 finished with value: 0.05388827994465828 and parameters: {'batch_size': 64, 'image_size': 192, 'max_epochs': 35, 'accumulate_grad_batches': 2, 'precision': '16-mixed', 'optimizer': 'AdamW', 'learning_rate': 0.004531271602426265, 'weight_decay': 6.593933792068769e-06, 'scheduler': 'StepLR', 'model_classifier_layers': 2}. Best is trial 12 with value: 0.03660617768764496.\n",
      "Best trial:\n",
      "{'batch_size': 64, 'image_size': 256, 'max_epochs': 24, 'accumulate_grad_batches': 1, 'precision': 32, 'optimizer': 'AdamW', 'learning_rate': 0.0024603367683237068, 'weight_decay': 0.00016334996012291853, 'scheduler': 'StepLR', 'model_classifier_layers': 2}\n",
      "Best value (val_loss): 0.03660617768764496\n"
     ]
    }
   ],
   "source": [
    "from models.model_transferlearning import getResNet152D_model\n",
    "\n",
    "import datetime\n",
    "config['sweep_id'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "config['image_size'] = 224\n",
    "def objective(trial):\n",
    "    model = getResNet152D_model\n",
    "    trainer = TLOptunaTrainer(\n",
    "        model=model,                        # Function to create the model\n",
    "        config=config,\n",
    "        normalize_mean=[0.485, 0.456, 0.406], \n",
    "        normalize_std=[0.229, 0.224, 0.225],\n",
    "        dataset_name=\"DwarfRabbits-binary\"\n",
    "    )\n",
    "    return trainer.run_training(trial)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")  # because we minimize val_loss\n",
    "\n",
    "# Set verbosity to WARNING to reduce output clutter\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# Start the hyperparameter optimization\n",
    "study.optimize(objective, n_trials=config['number_of_trials'], gc_after_trial=True, show_progress_bar=True)\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best value (val_loss):\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84da1a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.07259383797645569,
          0.07768524438142776,
          0.08053471148014069,
          0.20566357672214508,
          0.054816488176584244,
          0.07120317220687866,
          0.13220319151878357,
          0.06417486071586609,
          0.066299669444561,
          0.045927390456199646,
          0.05928408354520798,
          0.06056899204850197,
          0.03660617768764496,
          0.05338548123836517,
          0.04057195037603378,
          0.04454837366938591,
          0.07360348105430603,
          0.09316893666982651,
          0.03849393501877785,
          0.05388827994465828
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.07259383797645569,
          0.07259383797645569,
          0.07259383797645569,
          0.07259383797645569,
          0.054816488176584244,
          0.054816488176584244,
          0.054816488176584244,
          0.054816488176584244,
          0.054816488176584244,
          0.045927390456199646,
          0.045927390456199646,
          0.045927390456199646,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496,
          0.03660617768764496
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57486ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "precision (CategoricalDistribution): 0.007106540045219065<extra></extra>",
          "image_size (CategoricalDistribution): 0.02320940962217462<extra></extra>",
          "max_epochs (IntDistribution): 0.024705356127884562<extra></extra>",
          "scheduler (CategoricalDistribution): 0.051031780233704076<extra></extra>",
          "accumulate_grad_batches (CategoricalDistribution): 0.06704931889755573<extra></extra>",
          "learning_rate (FloatDistribution): 0.09194455641429579<extra></extra>",
          "batch_size (CategoricalDistribution): 0.11326613758076857<extra></extra>",
          "model_classifier_layers (IntDistribution): 0.14350597029310017<extra></extra>",
          "weight_decay (FloatDistribution): 0.15775855878755027<extra></extra>",
          "optimizer (CategoricalDistribution): 0.320422371997747<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.02",
          "0.05",
          "0.07",
          "0.09",
          "0.11",
          "0.14",
          "0.16",
          "0.32"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.007106540045219065,
          0.02320940962217462,
          0.024705356127884562,
          0.051031780233704076,
          0.06704931889755573,
          0.09194455641429579,
          0.11326613758076857,
          0.14350597029310017,
          0.15775855878755027,
          0.320422371997747
         ],
         "y": [
          "precision",
          "image_size",
          "max_epochs",
          "scheduler",
          "accumulate_grad_batches",
          "learning_rate",
          "batch_size",
          "model_classifier_layers",
          "weight_decay",
          "optimizer"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e1ff0",
   "metadata": {},
   "source": [
    "### ConvNextV2: Training and Logging with Weights & Biases including Hyper-Parameter Tuning\n",
    "\n",
    "In this step, we initialize the Weights & Biases (wandb) logger to track experiment metrics, hyperparameters, and model checkpoints. The logger is configured with project and experiment names, as well as key training parameters such as dataset, batch size, maximum epochs, and learning rate.\n",
    "\n",
    "We then set up the PyTorch Lightning `Trainer` with the wandb logger and an early stopping callback to monitor validation loss. The model is trained using the specified datamodule, and all relevant metrics are automatically logged to wandb for further analysis and visualization. After training, wandb logging is finalized to ensure all data is properly saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b83af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 16:53:37,710] A new study created in memory with name: no-name-df51e347-fc52-494d-92ff-c210c62a565b\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_165338-z524et7n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z524et7n' target=\"_blank\">TL_ConvNextV2_base_cls2_bs32_img192_optAdamW_lr2e-03_wd3e-06_sch_None_2025-06-17_16-53</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z524et7n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z524et7n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 88.0 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "88.0 M    Total params\n",
      "351.822   Total estimated model params size (MB)\n",
      "476       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▁▅▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆███████████</td></tr><tr><td>train_acc</td><td>▁▇▇█</td></tr><tr><td>train_loss</td><td>▃▁▁▂█▁▁▁▁▁▇▃▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>██▁▁</td></tr><tr><td>val_loss</td><td>▁▅█▇</td></tr><tr><td>val_precision</td><td>▁▂█▄</td></tr><tr><td>val_recall</td><td>█▇▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99975</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.99787</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>trainer/global_step</td><td>543</td></tr><tr><td>val_acc</td><td>0.99248</td></tr><tr><td>val_loss</td><td>0.02694</td></tr><tr><td>val_precision</td><td>0.99731</td></tr><tr><td>val_recall</td><td>0.98773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls2_bs32_img192_optAdamW_lr2e-03_wd3e-06_sch_None_2025-06-17_16-53</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z524et7n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z524et7n</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 15 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_165338-z524et7n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.026944497600197792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_165856-k5gj201q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/k5gj201q' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr1e-03_wd4e-05_sch_CosineAnnealingLR_2025-06-17_16-58</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/k5gj201q' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/k5gj201q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▆▇▇▇▇▇█▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇██████████</td></tr><tr><td>train_loss</td><td>▄▃▄▃▄▂▃▂▃▁▅▁█▂▇▃▂▁▂▂▂▂▁▁▂▁▂▂▂▁▂▂▂▁▁▇▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇████</td></tr><tr><td>val_acc</td><td>▆▇█▇▃▂▅▁▅▁▃▁▂▂▂</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▄▄▄▄▆▇▆▇▇▇███</td></tr><tr><td>val_recall</td><td>██▇▇▅▄▄▁▄▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99983</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>train_acc</td><td>0.99649</td></tr><tr><td>train_loss</td><td>0.019</td></tr><tr><td>trainer/global_step</td><td>4079</td></tr><tr><td>val_acc</td><td>0.9914</td></tr><tr><td>val_loss</td><td>0.01985</td></tr><tr><td>val_precision</td><td>0.99623</td></tr><tr><td>val_recall</td><td>0.98666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr1e-03_wd4e-05_sch_CosineAnnealingLR_2025-06-17_16-58</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/k5gj201q' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/k5gj201q</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 48 media file(s), 58 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_165856-k5gj201q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.01984698697924614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_173108-gcpcqrjl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gcpcqrjl' target=\"_blank\">TL_ConvNextV2_base_cls2_bs128_img224_optAdam_lr4e-03_wd1e-04_sch_StepLR_2025-06-17_17-31</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gcpcqrjl' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gcpcqrjl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 88.0 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "88.0 M    Total params\n",
      "351.822   Total estimated model params size (MB)\n",
      "476       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▆▁▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆█████████</td></tr><tr><td>train_acc</td><td>▁███</td></tr><tr><td>train_loss</td><td>█▁▁▁▂▁▂▂▂▂▁▂▂▂▁▁▂▄▁▁▄▁▃▂▂▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁█▃▅</td></tr><tr><td>val_loss</td><td>▁▃█▄</td></tr><tr><td>val_precision</td><td>▁▇█▂</td></tr><tr><td>val_recall</td><td>▂█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99979</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.99724</td></tr><tr><td>train_loss</td><td>0.00236</td></tr><tr><td>trainer/global_step</td><td>271</td></tr><tr><td>val_acc</td><td>0.99328</td></tr><tr><td>val_loss</td><td>0.02502</td></tr><tr><td>val_precision</td><td>0.99518</td></tr><tr><td>val_recall</td><td>0.99146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls2_bs128_img224_optAdam_lr4e-03_wd1e-04_sch_StepLR_2025-06-17_17-31</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gcpcqrjl' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gcpcqrjl</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 15 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_173108-gcpcqrjl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.0250166654586792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_173816-9vi345qi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9vi345qi' target=\"_blank\">TL_ConvNextV2_base_cls2_bs128_img224_optAdamW_lr8e-03_wd7e-03_sch_StepLR_2025-06-17_17-38</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9vi345qi' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9vi345qi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 88.0 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "88.0 M    Total params\n",
      "351.822   Total estimated model params size (MB)\n",
      "476       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▁▅▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆▆█████</td></tr><tr><td>train_acc</td><td>▁███</td></tr><tr><td>train_loss</td><td>█▁▃▁▇▂▂▅▁▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇████</td></tr><tr><td>val_acc</td><td>▁██▃</td></tr><tr><td>val_loss</td><td>▁▄▄█</td></tr><tr><td>val_precision</td><td>█▁▂█</td></tr><tr><td>val_recall</td><td>▁█▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99977</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.99759</td></tr><tr><td>train_loss</td><td>0.0059</td></tr><tr><td>trainer/global_step</td><td>135</td></tr><tr><td>val_acc</td><td>0.99248</td></tr><tr><td>val_loss</td><td>0.03256</td></tr><tr><td>val_precision</td><td>0.99677</td></tr><tr><td>val_recall</td><td>0.98826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls2_bs128_img224_optAdamW_lr8e-03_wd7e-03_sch_StepLR_2025-06-17_17-38</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9vi345qi' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/9vi345qi</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 15 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_173816-9vi345qi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.032562997192144394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_174424-ga8yo1rz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ga8yo1rz' target=\"_blank\">TL_ConvNextV2_base_cls1_bs128_img192_optSGD_lr1e-03_wd8e-06_sch_CosineAnnealingLR_2025-06-17_17-44</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ga8yo1rz' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ga8yo1rz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁██████████████████████████████████</td></tr><tr><td>train_loss</td><td>██▅▆▅▄▃▂▇▅▃▂▃▂▃▂▃▂▆▂▂▂▁▂▁▃▁▁▂▁▂▅▃▂▂▂▂▅▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_recall</td><td>█▁▂▂▂▂▂▄▄▄▅▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99977</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>train_acc</td><td>0.99385</td></tr><tr><td>train_loss</td><td>0.05052</td></tr><tr><td>trainer/global_step</td><td>1189</td></tr><tr><td>val_acc</td><td>0.99248</td></tr><tr><td>val_loss</td><td>0.02592</td></tr><tr><td>val_precision</td><td>0.992</td></tr><tr><td>val_recall</td><td>0.99306</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs128_img192_optSGD_lr1e-03_wd8e-06_sch_CosineAnnealingLR_2025-06-17_17-44</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ga8yo1rz' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ga8yo1rz</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 108 media file(s), 112 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_174424-ga8yo1rz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.025921113789081573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_181814-3bqwmj3z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/3bqwmj3z' target=\"_blank\">TL_ConvNextV2_base_cls2_bs64_img192_optSGD_lr6e-04_wd1e-05_sch_CosineAnnealingLR_2025-06-17_18-18</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/3bqwmj3z' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/3bqwmj3z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 88.0 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "88.0 M    Total params\n",
      "351.822   Total estimated model params size (MB)\n",
      "476       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▄▅▆▆▇▇▇▇▇▇███████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁██████████████████████████████████</td></tr><tr><td>train_loss</td><td>██▄▂▂▂▂▂▁▁▁▃▃▅▃▂▂▁▂▆▃▁▁▁▁▁▁▁▁▁▁▅▁▁▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▄▄▅▅▅▅▆▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▆▆▆▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_recall</td><td>▁▂▃▃▃▄▄▄▆▇▇▇▇▇▇▇▇▇▇██████████▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99975</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>train_acc</td><td>0.99489</td></tr><tr><td>train_loss</td><td>0.00251</td></tr><tr><td>trainer/global_step</td><td>4759</td></tr><tr><td>val_acc</td><td>0.99248</td></tr><tr><td>val_loss</td><td>0.02207</td></tr><tr><td>val_precision</td><td>0.99253</td></tr><tr><td>val_recall</td><td>0.99253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls2_bs64_img192_optSGD_lr6e-04_wd1e-05_sch_CosineAnnealingLR_2025-06-17_18-18</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/3bqwmj3z' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/3bqwmj3z</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 108 media file(s), 106 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_181814-3bqwmj3z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.02207384631037712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_191504-rpf67q08</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/rpf67q08' target=\"_blank\">TL_ConvNextV2_base_cls1_bs32_img192_optAdam_lr1e-03_wd1e-04_sch_StepLR_2025-06-17_19-15</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/rpf67q08' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/rpf67q08</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▅▅█▇▁▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>train_acc</td><td>▁▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>val_acc</td><td>██▁▇▇▄▆</td></tr><tr><td>val_loss</td><td>█▃▂▁▂▂▂</td></tr><tr><td>val_precision</td><td>▂▂█▂▁▆▁</td></tr><tr><td>val_recall</td><td>██▁▇█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99973</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>train_acc</td><td>0.99776</td></tr><tr><td>train_loss</td><td>0.0016</td></tr><tr><td>trainer/global_step</td><td>1903</td></tr><tr><td>val_acc</td><td>0.99301</td></tr><tr><td>val_loss</td><td>0.02101</td></tr><tr><td>val_precision</td><td>0.99306</td></tr><tr><td>val_recall</td><td>0.99306</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs32_img192_optAdam_lr1e-03_wd1e-04_sch_StepLR_2025-06-17_19-15</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/rpf67q08' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/rpf67q08</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 24 media file(s), 32 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_191504-rpf67q08\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.021006060764193535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_192356-s8jdqi4o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s8jdqi4o' target=\"_blank\">TL_ConvNextV2_base_cls1_bs32_img224_optAdam_lr7e-04_wd7e-03_sch_None_2025-06-17_19-23</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s8jdqi4o' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s8jdqi4o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▅▅▇▆▇▇▅██▇█▆▅▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▇▇████████████</td></tr><tr><td>train_loss</td><td>█▃▃▄▂▅▁▁▂▂▂▂▁▁▇▁▁▂▁▁▁▁▂▁▁▁▅▁▁▁▂▁▁▁▂▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▆▁▆▃▆▆▅▆▇▃█▃▃▃</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▂▁▁▁▁▂▁▁</td></tr><tr><td>val_precision</td><td>▁▂▄▃▇▄▅█▅▄▆▅▇▇▇</td></tr><tr><td>val_recall</td><td>▇█▂▇▁▅▅▁▅▆▁▆▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99979</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>train_acc</td><td>0.99724</td></tr><tr><td>train_loss</td><td>0.00117</td></tr><tr><td>trainer/global_step</td><td>2039</td></tr><tr><td>val_acc</td><td>0.9914</td></tr><tr><td>val_loss</td><td>0.02059</td></tr><tr><td>val_precision</td><td>0.99569</td></tr><tr><td>val_recall</td><td>0.98719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs32_img224_optAdam_lr7e-04_wd7e-03_sch_None_2025-06-17_19-23</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s8jdqi4o' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/s8jdqi4o</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 48 media file(s), 64 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_192356-s8jdqi4o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.02058873325586319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_194305-vhmvxj9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vhmvxj9r' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img192_optSGD_lr8e-04_wd5e-05_sch_CosineAnnealingLR_2025-06-17_19-43</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vhmvxj9r' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vhmvxj9r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=38` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▆▇▇▇████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>▆▃█▅▂▄▃▃▂▂▂▂▁▁▁▄▂▃▂▁▂▁▂▂▅▁▁▂▁▂▁▂▂▁▂▆▂▁▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▄▄▆▇▇▇▇▇██▇▇▇▇▆▅▅▆▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>val_recall</td><td>▂▄▄▇▇▇▇▇▇██▇▇▇▇▅▄▄▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99977</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>train_acc</td><td>0.99598</td></tr><tr><td>train_loss</td><td>0.00308</td></tr><tr><td>trainer/global_step</td><td>5167</td></tr><tr><td>val_acc</td><td>0.99221</td></tr><tr><td>val_loss</td><td>0.02117</td></tr><tr><td>val_precision</td><td>0.99411</td></tr><tr><td>val_recall</td><td>0.99039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img192_optSGD_lr8e-04_wd5e-05_sch_CosineAnnealingLR_2025-06-17_19-43</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vhmvxj9r' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vhmvxj9r</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 117 media file(s), 104 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_194305-vhmvxj9r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.02117064595222473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_202649-mi3vr61y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mi3vr61y' target=\"_blank\">TL_ConvNextV2_base_cls1_bs32_img256_optSGD_lr7e-03_wd2e-04_sch_StepLR_2025-06-17_20-26</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mi3vr61y' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mi3vr61y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▄▇▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆██████████</td></tr><tr><td>train_acc</td><td>▁▇▇█</td></tr><tr><td>train_loss</td><td>▁▁▁▁▃▁▂▁▁▃▁▁█▁▃▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇███</td></tr><tr><td>val_acc</td><td>█▅▃▁</td></tr><tr><td>val_loss</td><td>▁▆▃█</td></tr><tr><td>val_precision</td><td>▁█▆▄</td></tr><tr><td>val_recall</td><td>█▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99981</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.99736</td></tr><tr><td>train_loss</td><td>0.0084</td></tr><tr><td>trainer/global_step</td><td>2175</td></tr><tr><td>val_acc</td><td>0.9914</td></tr><tr><td>val_loss</td><td>0.01921</td></tr><tr><td>val_precision</td><td>0.99569</td></tr><tr><td>val_recall</td><td>0.98719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs32_img256_optSGD_lr7e-03_wd2e-04_sch_StepLR_2025-06-17_20-26</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mi3vr61y' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/mi3vr61y</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 15 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_202649-mi3vr61y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.019206510856747627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_203350-gwrmp2mp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gwrmp2mp' target=\"_blank\">TL_ConvNextV2_base_cls1_bs32_img256_optSGD_lr1e-04_wd8e-04_sch_StepLR_2025-06-17_20-33</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gwrmp2mp' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gwrmp2mp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=24` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▅▆▆▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇███████████████████</td></tr><tr><td>train_loss</td><td>▄▅▄▃▃▁▂▆▂▁▂▁▂▃▁▂▃▂▁▅▁▁▁▁▂█▁▂▆▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▂▄▄▆▆▇▇▇███▇▇▇▇▇▇▇▇▇▆▆▆</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▄▄▆▆▇▇▇███████████████</td></tr><tr><td>val_recall</td><td>▅▅▆▅████████▆▆▆▅▅▅▅▅▅▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99979</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>train_acc</td><td>0.99511</td></tr><tr><td>train_loss</td><td>0.01598</td></tr><tr><td>trainer/global_step</td><td>13055</td></tr><tr><td>val_acc</td><td>0.99087</td></tr><tr><td>val_loss</td><td>0.02307</td></tr><tr><td>val_precision</td><td>0.99145</td></tr><tr><td>val_recall</td><td>0.99039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs32_img256_optSGD_lr1e-04_wd8e-04_sch_StepLR_2025-06-17_20-33</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gwrmp2mp' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/gwrmp2mp</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 75 media file(s), 74 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_203350-gwrmp2mp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.02306986041367054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_211327-np54m415</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/np54m415' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr2e-04_wd5e-04_sch_CosineAnnealingLR_2025-06-17_21-13</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/np54m415' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/np54m415</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=21` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▃▅▆▆▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▇███████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▃▆▆▆▆▆▆▆▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▄▆▆▆▆▆▆▆▇▇▇█████████</td></tr><tr><td>val_recall</td><td>█▅▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.9998</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>train_acc</td><td>0.99391</td></tr><tr><td>train_loss</td><td>0.01347</td></tr><tr><td>trainer/global_step</td><td>5711</td></tr><tr><td>val_acc</td><td>0.99275</td></tr><tr><td>val_loss</td><td>0.02631</td></tr><tr><td>val_precision</td><td>0.99306</td></tr><tr><td>val_recall</td><td>0.99253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr2e-04_wd5e-04_sch_CosineAnnealingLR_2025-06-17_21-13</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/np54m415' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/np54m415</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 66 media file(s), 66 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_211327-np54m415\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.026305777952075005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_220413-z1zwwnra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z1zwwnra' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr1e-02_wd4e-04_sch_StepLR_2025-06-17_22-04</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z1zwwnra' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z1zwwnra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▂█▆▇▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▇▇███</td></tr><tr><td>train_loss</td><td>▅▄▁▃▁▄▂▁▂▂▁▁▁▁█▂▂▂▁▂▅▂▁▂▁▁▂▇▂▃▂▂▁▁▂▁▁▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▂▁▇▅█▂</td></tr><tr><td>val_loss</td><td>▇█▁▂▁▆</td></tr><tr><td>val_precision</td><td>██▁▁▁▁</td></tr><tr><td>val_recall</td><td>▂▁▇▅█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99983</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.9977</td></tr><tr><td>train_loss</td><td>0.00087</td></tr><tr><td>trainer/global_step</td><td>1631</td></tr><tr><td>val_acc</td><td>0.9914</td></tr><tr><td>val_loss</td><td>0.01868</td></tr><tr><td>val_precision</td><td>0.99623</td></tr><tr><td>val_recall</td><td>0.98666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr1e-02_wd4e-04_sch_StepLR_2025-06-17_22-04</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z1zwwnra' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/z1zwwnra</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 21 media file(s), 28 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_220413-z1zwwnra\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.018681326881051064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_223629-npzaa79n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/npzaa79n' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr8e-03_wd8e-04_sch_StepLR_2025-06-17_22-36</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/npzaa79n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/npzaa79n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▇▇▁█▅▅▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▂▂▂▁▁▂▂▃▂▁▁▂▁▂▁█▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇███</td></tr><tr><td>val_acc</td><td>▁▅▆▁█▄▃▅</td></tr><tr><td>val_loss</td><td>▆▂▂█▁▃▃▃</td></tr><tr><td>val_precision</td><td>▁▂▇█▇███</td></tr><tr><td>val_recall</td><td>▅█▆▁█▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99982</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_acc</td><td>0.99776</td></tr><tr><td>train_loss</td><td>0.00248</td></tr><tr><td>trainer/global_step</td><td>2175</td></tr><tr><td>val_acc</td><td>0.99167</td></tr><tr><td>val_loss</td><td>0.01857</td></tr><tr><td>val_precision</td><td>0.9957</td></tr><tr><td>val_recall</td><td>0.98773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr8e-03_wd8e-04_sch_StepLR_2025-06-17_22-36</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/npzaa79n' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/npzaa79n</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 27 media file(s), 36 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_223629-npzaa79n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.018565520644187927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_231106-cykjkk88</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/cykjkk88' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optAdamW_lr3e-03_wd1e-03_sch_StepLR_2025-06-17_23-11</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/cykjkk88' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/cykjkk88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▇▅▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆██████████</td></tr><tr><td>train_acc</td><td>▁▇██</td></tr><tr><td>train_loss</td><td>▃▃▃▁▄▂█▃▂▂▂▁▂▂▂▂▁▁▅▁▂▁▂▁▅▁▂▁▃▁▁▁▂▁▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>val_acc</td><td>▇▃█▁</td></tr><tr><td>val_loss</td><td>▁▃▄█</td></tr><tr><td>val_precision</td><td>▁█▁▁</td></tr><tr><td>val_recall</td><td>▇▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99959</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.99764</td></tr><tr><td>train_loss</td><td>0.00561</td></tr><tr><td>trainer/global_step</td><td>1087</td></tr><tr><td>val_acc</td><td>0.99087</td></tr><tr><td>val_loss</td><td>0.02426</td></tr><tr><td>val_precision</td><td>0.99516</td></tr><tr><td>val_recall</td><td>0.98666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optAdamW_lr3e-03_wd1e-03_sch_StepLR_2025-06-17_23-11</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/cykjkk88' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/cykjkk88</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 15 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_231106-cykjkk88\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.024258168414235115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_232055-ft50vgrw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ft50vgrw' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr4e-03_wd1e-03_sch_StepLR_2025-06-17_23-20</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ft50vgrw' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ft50vgrw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▅▆▃▅█▆▇▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▇▇██████</td></tr><tr><td>train_loss</td><td>█▂▆▁▂▁▂▃▁▁▂▂▁▁▇▁▁▃▃▃▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▄▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▄▄▄▇█▅▇▇</td></tr><tr><td>val_loss</td><td>█▄▃▄▃▁▃▂▂</td></tr><tr><td>val_precision</td><td>▁▄▆██▇███</td></tr><tr><td>val_recall</td><td>█▆▃▁▃▆▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99985</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_acc</td><td>0.99741</td></tr><tr><td>train_loss</td><td>0.01115</td></tr><tr><td>trainer/global_step</td><td>2447</td></tr><tr><td>val_acc</td><td>0.99221</td></tr><tr><td>val_loss</td><td>0.01779</td></tr><tr><td>val_precision</td><td>0.99677</td></tr><tr><td>val_recall</td><td>0.98773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr4e-03_wd1e-03_sch_StepLR_2025-06-17_23-20</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ft50vgrw' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ft50vgrw</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 30 media file(s), 38 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_232055-ft50vgrw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.017790257930755615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_233604-ekpuhapq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ekpuhapq' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr4e-03_wd2e-03_sch_StepLR_2025-06-17_23-36</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ekpuhapq' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ekpuhapq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄▃▅▆▇██▇▇▆</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▇▇▇███████</td></tr><tr><td>train_loss</td><td>▃▃▂▂▂▂▃▅▄▃▃█▄▃▂▁▇▁▁▂▄▁▁▂▁▂▁▁▁▃▁▁▁▂▂▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▇▄▁▄▃▄▆█▅▅▄</td></tr><tr><td>val_loss</td><td>█▄▄▃▂▂▁▁▂▂▂</td></tr><tr><td>val_precision</td><td>▁▂▇█▆▇▇▇███</td></tr><tr><td>val_recall</td><td>█▅▁▂▃▃▅▆▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99983</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.99747</td></tr><tr><td>train_loss</td><td>0.01624</td></tr><tr><td>trainer/global_step</td><td>2991</td></tr><tr><td>val_acc</td><td>0.9914</td></tr><tr><td>val_loss</td><td>0.01913</td></tr><tr><td>val_precision</td><td>0.99569</td></tr><tr><td>val_recall</td><td>0.98719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optSGD_lr4e-03_wd2e-03_sch_StepLR_2025-06-17_23-36</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ekpuhapq' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ekpuhapq</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 36 media file(s), 48 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_233604-ekpuhapq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.01912606693804264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250617_235435-totu4rrm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/totu4rrm' target=\"_blank\">TL_ConvNextV2_base_cls2_bs64_img256_optSGD_lr5e-03_wd2e-03_sch_None_2025-06-17_23-54</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/totu4rrm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/totu4rrm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 88.0 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "88.0 M    Total params\n",
      "351.822   Total estimated model params size (MB)\n",
      "476       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▁▄█▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▇████</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▆▇██▇</td></tr><tr><td>val_loss</td><td>█▃▁▂▁▂</td></tr><tr><td>val_precision</td><td>▁▇▇███</td></tr><tr><td>val_recall</td><td>█▁█▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99983</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.99695</td></tr><tr><td>train_loss</td><td>0.00129</td></tr><tr><td>trainer/global_step</td><td>1631</td></tr><tr><td>val_acc</td><td>0.99194</td></tr><tr><td>val_loss</td><td>0.01891</td></tr><tr><td>val_precision</td><td>0.99677</td></tr><tr><td>val_recall</td><td>0.98719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls2_bs64_img256_optSGD_lr5e-03_wd2e-03_sch_None_2025-06-17_23-54</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/totu4rrm' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/totu4rrm</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 21 media file(s), 28 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250617_235435-totu4rrm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.018910454586148262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250618_000511-ojjkvjig</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ojjkvjig' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optAdamW_lr4e-03_wd3e-03_sch_StepLR_2025-06-18_00-05</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ojjkvjig' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ojjkvjig</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning:\n",
      "\n",
      "A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> █▇▇▁▅▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█████</td></tr><tr><td>train_acc</td><td>▁▆▇███</td></tr><tr><td>train_loss</td><td>▇▆█▂▃▁▂▁▂▁▁▁▃▁▁▁▁▁▁▁█▁▂▁▁▁▂▁▁▁▂▁▂▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▆▆█▄▄▁</td></tr><tr><td>val_loss</td><td>▂▂▁█▅▆</td></tr><tr><td>val_precision</td><td>▆█▄▇▄▁</td></tr><tr><td>val_recall</td><td>▄▃█▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99978</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.99897</td></tr><tr><td>train_loss</td><td>0.02666</td></tr><tr><td>trainer/global_step</td><td>1631</td></tr><tr><td>val_acc</td><td>0.98952</td></tr><tr><td>val_loss</td><td>0.02162</td></tr><tr><td>val_precision</td><td>0.99038</td></tr><tr><td>val_recall</td><td>0.98879</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optAdamW_lr4e-03_wd3e-03_sch_StepLR_2025-06-18_00-05</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ojjkvjig' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/ojjkvjig</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 21 media file(s), 28 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250618_000511-ojjkvjig\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.021624010056257248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning:\n",
      "\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20250618_001542-vcxflsfd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vcxflsfd' target=\"_blank\">TL_ConvNextV2_base_cls1_bs64_img256_optAdam_lr2e-03_wd4e-04_sch_StepLR_2025-06-18_00-15</a></strong> to <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vcxflsfd' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vcxflsfd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | ConvNeXt          | 87.7 M | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | sigmoid        | Sigmoid           | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "5 | val_precision  | BinaryPrecision   | 0      | train\n",
      "6 | val_recall     | BinaryRecall      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "87.7 M    Non-trainable params\n",
      "87.7 M    Total params\n",
      "350.775   Total estimated model params size (MB)\n",
      "471       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning:\n",
      "\n",
      "A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1179: UndefinedMetricWarning:\n",
      "\n",
      "No negative samples in y_true, false positive value should be meaningless\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryAccuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryPrecision was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n",
      "c:\\Users\\lukas\\anaconda3\\envs\\VDKI-Projekt\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning:\n",
      "\n",
      "The ``compute`` method of metric BinaryRecall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td> ▅██▁▅▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▇▇▇▇▇▇████████</td></tr><tr><td>train_acc</td><td>▁▇▇███</td></tr><tr><td>train_loss</td><td>█▂▅▅▃▂▂▁▂▂▂▁▁▁▂▁▅▁▂▂▁▁▂▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁▇█▄▂▃</td></tr><tr><td>val_loss</td><td>▄▁▁█▄▂</td></tr><tr><td>val_precision</td><td>▄▄▅█▄▁</td></tr><tr><td>val_recall</td><td>▁▇█▁▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Data ROC AUC</td><td>0.99979</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.9981</td></tr><tr><td>train_loss</td><td>0.05747</td></tr><tr><td>trainer/global_step</td><td>1631</td></tr><tr><td>val_acc</td><td>0.99167</td></tr><tr><td>val_loss</td><td>0.01914</td></tr><tr><td>val_precision</td><td>0.99357</td></tr><tr><td>val_recall</td><td>0.98986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TL_ConvNextV2_base_cls1_bs64_img256_optAdam_lr2e-03_wd4e-04_sch_StepLR_2025-06-18_00-15</strong> at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vcxflsfd' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext/runs/vcxflsfd</a><br> View project at: <a href='https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext' target=\"_blank\">https://wandb.ai/HKA-EKG-Signalverarbeitung/VDKI-Hasen_Hyperparameter_Tuning_TL_ConvNext</a><br>Synced 5 W&B file(s), 21 media file(s), 26 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250618_001542-vcxflsfd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Validation loss: 0.019135424867272377\n",
      "Best trial:\n",
      "{'batch_size': 64, 'image_size': 256, 'max_epochs': 23, 'accumulate_grad_batches': 1, 'precision': '16-mixed', 'optimizer': 'SGD', 'learning_rate': 0.0042486420781319215, 'weight_decay': 0.0014540551521945075, 'scheduler': 'StepLR', 'model_classifier_layers': 1}\n",
      "Best value (val_loss): 0.017790257930755615\n"
     ]
    }
   ],
   "source": [
    "from models.model_transferlearning import getConvNextV2_model\n",
    "\n",
    "import datetime\n",
    "config['sweep_id'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "config['image_size'] = 224\n",
    "def objective(trial):\n",
    "    model_fct = getConvNextV2_model\n",
    "    trainer = TLOptunaTrainer(\n",
    "        model=model_fct,                        # Function to create the model\n",
    "        config=config,\n",
    "        normalize_mean=[0.485, 0.456, 0.406], \n",
    "        normalize_std=[0.229, 0.224, 0.225],\n",
    "        dataset_name=\"DwarfRabbits-binary\"\n",
    "    )\n",
    "    return trainer.run_training(trial)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")  # because we minimize val_loss\n",
    "\n",
    "# Set verbosity to WARNING to reduce output clutter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Start the hyperparameter optimization\n",
    "study.optimize(objective, n_trials=config['number_of_trials'])\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best value (val_loss):\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9eb53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.026944497600197792,
          0.01984698697924614,
          0.0250166654586792,
          0.032562997192144394,
          0.025921113789081573,
          0.02207384631037712,
          0.021006060764193535,
          0.02058873325586319,
          0.02117064595222473,
          0.019206510856747627,
          0.02306986041367054,
          0.026305777952075005,
          0.018681326881051064,
          0.018565520644187927,
          0.024258168414235115,
          0.017790257930755615,
          0.01912606693804264,
          0.018910454586148262,
          0.021624010056257248,
          0.019135424867272377
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.026944497600197792,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.01984698697924614,
          0.019206510856747627,
          0.019206510856747627,
          0.019206510856747627,
          0.018681326881051064,
          0.018565520644187927,
          0.018565520644187927,
          0.017790257930755615,
          0.017790257930755615,
          0.017790257930755615,
          0.017790257930755615,
          0.017790257930755615
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98690da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "scheduler (CategoricalDistribution): 0.0140457736514318<extra></extra>",
          "max_epochs (IntDistribution): 0.019025162920142346<extra></extra>",
          "image_size (CategoricalDistribution): 0.020897989698966873<extra></extra>",
          "precision (CategoricalDistribution): 0.050734561096992786<extra></extra>",
          "model_classifier_layers (IntDistribution): 0.05373546106604905<extra></extra>",
          "weight_decay (FloatDistribution): 0.05701278655233838<extra></extra>",
          "optimizer (CategoricalDistribution): 0.1050907372195977<extra></extra>",
          "accumulate_grad_batches (CategoricalDistribution): 0.16845399572070466<extra></extra>",
          "learning_rate (FloatDistribution): 0.24856344704721162<extra></extra>",
          "batch_size (CategoricalDistribution): 0.2624400850265648<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.01",
          "0.02",
          "0.02",
          "0.05",
          "0.05",
          "0.06",
          "0.11",
          "0.17",
          "0.25",
          "0.26"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0140457736514318,
          0.019025162920142346,
          0.020897989698966873,
          0.050734561096992786,
          0.05373546106604905,
          0.05701278655233838,
          0.1050907372195977,
          0.16845399572070466,
          0.24856344704721162,
          0.2624400850265648
         ],
         "y": [
          "scheduler",
          "max_epochs",
          "image_size",
          "precision",
          "model_classifier_layers",
          "weight_decay",
          "optimizer",
          "accumulate_grad_batches",
          "learning_rate",
          "batch_size"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDKI-Projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
